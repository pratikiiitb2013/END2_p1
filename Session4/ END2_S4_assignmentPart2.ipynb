{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_S4_assignmentPart2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikiiitb2013/END2_p1/blob/main/Session4/%20END2_S4_assignmentPart2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a4abd1-09dd-4a77-e4e1-2e001e05a2ab"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x)) \n",
        "\n",
        "def dsigmoid(y): \n",
        "  return y*(1-y)\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x) \n",
        "\n",
        "def dtanh(y): \n",
        "  return 1 - y**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcu6AXwsEfko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a908b5-beba-4148-b166-e20587572194"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLS3eRxqEfyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7bc3f8-7ea4-421f-9578-1d175f3cb03c"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb9PwTN_Ef2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5c7c52-859a-4744-cb08-b4f7b6fc6117"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCmYqVGoEf5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c5891d-9d50-499f-c280-13ffb0d3ec91"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCYRHgyCHPZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3e7807-f5d8-44f7-e135-87ca76a7e68d"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr0s3N5IHW-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1605387-66d6-44f5-a414-92a5aded6361"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "bdacd6c3-98b9-434a-8bf7-434d884e8b83"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1cH/8U8IOyiKyqKo4HZcqPq41iIVK9aFtv5aq/5aam21i61dfdpH3HEtVat9VGxRKbhbRRQ0FJBVdgLIDoctCSQBkpB9m0wy8/xxJ5NJZrJPZnIn3/frxYs7996599wEvnPnnHPPSfL7/YiIiDt1i3cBRESk7RTiIiIuphAXEXExhbiIiIspxEVEXKx7LE9mjOkFXAocBGpieW4REZdKBoYCqdZaT8ONMQ1xnABfFuNziogkgtHA8oYrYx3iBwHeeecdhgwZEuNTi4i4z6FDhxg/fjwE8rOhWId4DcCQIUMYNmxYjE8tIuJqEaug1bApIuJiCnERERdTiIuIuJhCXETExRTiIiIuphAXEXEx14T4GQ/M4a9zd8a7GCIinYprQrza5+cfS/bGuxgiIp2Ka0JcRETCKcRFRFxMIS4i4mIKcRERF1OIi4i4mEJcRMTFFOIiIi6mEBcRcTGFuIiIiynERURcTCEuIuJiCnERERdTiIuIuJhCXETExRTiIiIuphAXEXExhbiIiIspxEVEXEwhLiLiYgpxEREXU4iLiLiYQlxExMUU4iIiLqYQFxFxse4t2ckY8wwwOrD/X4BU4C0gGTgI3G6t9RhjxgN/AHzAq9baqR1SahERAVpwJ26MuRoYaa29Arge+DvwODDZWjsa2APcaYzpBzwCjAXGAH80xgzsqIKLiEjLqlO+AG4JLBcC/XBCenZg3ac4wX05kGqtLbLWVgArgFFRLa2IiNTTbHWKtbYGKAu8vAuYA1xnrfUE1uUAQ4EhQG7IW2vXi4hIB2lRnTiAMeYmnBD/JrA7ZFNSI29pbL2IiERJi3qnGGOuAx4EbrDWFgGlxpg+gc0nAdmBP0NC3la7XkREOkhLGjYHAM8C37LW5gdWLwBuDizfDMwF1gCXGmOOMcb0x6kPXxb9IouISK2WVKfcBhwPfGCMqV13B/C6MeaXQAbwhrXWa4yZAMwD/MBjgbt2ERHpIC1p2HwVeDXCpmsj7DsDmBGFcomISAvoiU0RERdTiIuIuJhCXETExRTiIiIuphAXEXExhbiIiIspxEVEXEwhLiLiYgpxEREXU4iLiLiYQlxExMUU4iIiLqYQFxFxMYW4iIiLKcRFRFxMIS4i4mIKcRERF1OIi4i4mEJcRMTFFOIiIi6mEBcRcTGFuIiIiynERURcrHu8C9BS3ZJg3PknxrsYIiKdimvuxIcc3Zve3V1TXBGRmFAqioi4mKtC3B/vAoiIdDKuCfGkpKR4F0FEpNNxTYhnFVaQV+qJdzFERDoV14Q4wBKbG+8iiIh0Kq4KcRERqU8hLiLiYgpxEREXU4iLiLhYix67N8aMBGYBL1hrXzbGTAcuBo4EdnnWWptijBkP/AHwAa9aa6d2QJlFRCSg2RA3xvQDXgIWNth0v7X2swb7PQJcBlQBqcaYj621+VEsr4iIhGhJdYoHuBHIbma/y4FUa22RtbYCWAGMamf5RESkCc3eiVtrq4FqY0zDTb8xxtwL5AC/AYYAoR25c4ChUSqniIhE0NaGzbeACdbabwAbgYkR9tFz8iIiHaxN44lba0Prx2cD/wBm4NyN1zoJWN32oomISHPadCdujPnIGHNa4OUYYCuwBrjUGHOMMaY/Tn34sqiUUkREImpJ75SLgb8BwwGvMeb7OL1V/m2MKQdKgZ9aayuMMROAeTijxj5mrS3qsJKLiEiLGjbX49xtN/RRhH1n4FSriIhIDOiJTRERF1OIi4i4mEJcRMTFFOIiIi7muhD/yqPz8Ps1ZbKICLgwxEs81SjDRUQcrgtxERGpoxAXEXExhbiIiIu5MsSTND6iiAjg0hAXERGHK0N82e68eBdBRKRTcGWIbzpQGO8iiIh0Cq4McXUTFxFxuDPEleIiIoBLQ7ygvCreRRAR6RRcGeLzth2KdxFERDoFV4b4waLKeBdBRKRTcGWIi4iIQyEuIuJirg3xQjVuioi4N8QvfPxzMo6UxbsYIiJx5doQBziQXxHvIoiIxJWrQ7ybRjMUkS7O1SH+ycaseBdBRCSuXB3iH6zL5InPtse7GCIicdM93gVor6nL0+jdoxu/ufpM+vRMjndxRERiytV34rUmL97LfR9tZmtWUbyLIiISUwkR4gCzN2XzrZeWx7sYIiIxlTAhLiLSFSnERURcLOFCfPiEFOZsORjvYoiIxIRrQnxAnx4t3nf6ivSOK4iISCfSoi6GxpiRwCzgBWvty8aYk4G3gGTgIHC7tdZjjBkP/AHwAa9aa6dGq6A+zckmIhKm2TtxY0w/4CVgYcjqx4HJ1trRwB7gzsB+jwBjgTHAH40xA6NV0DMG9W/xvrmlHr7cXxCtU4uIdFotqU7xADcC2SHrxgCzA8uf4gT35UCqtbbIWlsBrABGRaugJw7o0+J90/LK+O4rK6N1ahGRTqvZ6hRrbTVQbYwJXd3PWusJLOcAQ4EhQG7IPrXro0LVKSIi4aLRsNnYWIJRHWOw2tf6EB8+IYXn5tloFkNEpFNpa4iXGmNq6zdOwqlqyca5G6fB+qho6434y4v3RKsIIiKdTltDfAFwc2D5ZmAusAa41BhzjDGmP059+LL2F9HRI1mDh4uINNRsnbgx5mLgb8BwwGuM+T4wHphujPklkAG8Ya31GmMmAPMAP/CYtTZqI1Ldcskw/rP1ULQOJyKSEFrSsLkepzdKQ9dG2HcGMKP9xQp3fP9eHXFYERFXc80Tm+edOKDN7x0+IYWqal8USyMi0jm4JsST2zmh5tJduc3vJCLiMq4J8fZ66JMtrNiTF+9iiIhEVZcJ8cPFHsa/vibexRARiaouE+Kh7KES9uWWxrsYIiLt5vqJkltr+ISU4HL6pHFxLImISPt1yTtxEZFEoRAXEXExV4X4q7dfHO8iiIh0Kq4K8WP79Yzq8YZPSGFrVtRGBhARiTlXhXhHDCn+6eaoDbQoIhJzLgvxjpsYYsb6TIorvR12fBGRjuCqLoYdEeFTlu5jytJ9AHzLDuXlH17UAWcREekYrroT7+gp2nJLPMHl9LwyJmtCCRHp5Fx1Jz7ypLaPZNhat/9rDQfyK7jt0pM1DK6IdFquuhM/unePDj3+mrR8bvhfZzKiA/kVAGzPLu7Qc4qItIerQjwWdhwsrvdo/q7DJXEsjYhI0xTiIiIuphBvRlKSJmgWkc5LId6MQ0UVFFd6OVxcGe+iiIiEcV2I73zi+pie77VlaZw/cT6XP72Qden5lHqqY3p+EZGmuKqLIUDvHslxO/f3/7kKgN9dcya/HnN6XMsiIgIuDPHO4MWFu8ktqeTuq07n1OP6xbs4ItKFua46pbN4b+0Brnp2CQA5xZVs2F8Q3wKJSJekEI+Ca1/4gu+9shKAqmofmQXlcS6RiHQVCvEoKKqoG/1wwkebufKviymvUgOoiHQ8hXg73fPuhuDy3K2HmPllFgAer6/efpkF5fzX4/NJyyuLaflEJLEpxNspZfPB4PLdb68PLn+6OZtt2XWzBs3amE1BuZcP1h2IaflEJLEpxDvII7O2Me7F5WHrQ0fTfX3ZPoZPSKFMfc9FpI0U4jES6en96SvTAcgvq2r2/dmFFaqKEZEwrgzxcecPjXcR2szfxvmJvjZpEVc/tyS6hRER13NliPdMdlexD+SX141LHpLhHTxRkYh0Ae5Kw4CvnjYw3kVosZJKL6OfWcxngQbQKV/sY9SkRWH7zdlykDHPLqbGp2QXkZZr02P3xpgxwIfAtsCqLcAzwFtAMnAQuN1a64l4gHa69ZKTudoM4rKnF3bE4aPqKxPnh63LKqwIW/c/MzZT6qmmvKqaozp4BiMRSRztuRNfaq0dE/jzW+BxYLK1djSwB7gzKiWMICkpiUFH9+6ow8eFX3UrItIG0axOGQPMDix/CoyN4rETzosLd5NXGv5FRZNQiEhrtGcUw3ONMbOBgcBjQL+Q6pMcwL1dSGLg+c93BZeTkmhjnxUR6eraeie+Gye4bwLuAKZS/wNBt5OtcNuU1ZRX1QD1f3Bf7i9g0c7Dzb7fW+Pjw3UH8IU0ihaUVfGzN9ZR0II+6CLiXm0KcWttlrX239Zav7V2L3AIONYY0yewy0lAdrQKmehCGzoPFlWSmp4PwHdfWcmd09cxf9uhJt//zyV7+fOMzczalBVcN21lOgt2HOaNVenNnn//kXKGT0hha1ZRs/uKSOfSphA3xow3xvwpsDwEGAxMA24O7HIzMDcqJexixj6/lFv+uYqSyrqREX/x1vom3kGwbv3vC3bXrWxFQ+mCHc7d/oz1ma0oqcRScaWXjQcK410M6YTaWic+G3jXGHMT0BP4FfAl8KYx5pdABvBGdIrYNV385IKI6w/kl/P2mgzu/vrprNx7hPKqako9TlVMxpHwccyTVLOVEH46LZX1GQXseeoGurvsYTfpWG0KcWttCfDtCJuubV9xWufRb5/LY59uj+UpY6aq2hdx/ehnFgMwZem+Vh/TU11DZZWPAX3r90OPVoeYw8WVDHZR18+Js7exL6+MN++8LN5FadamwF24GsClIVd/pP901Aj6aLLieorKvczckMlHG7LqrU/LK8M8NJcLHp/PqEmLmL2prsmitvGz9mnRcS8u4/VlrfuQWLorl8ufXths/X1nMn1lOl/syo13MVpFjxNIQ64OcYjeXWSi+Pmb67j3g03BxtJqn4/iSi8fhoxjnlVYwYMztwRfv7hoD+AE8aGiSrZlF/Nkyo7g9owjZbyyZE/YuUo91cHg3xy4U9yUmdj1to/O2spd01Njft7af+dtHUBNEpfrQ1zqWxvo2VLrpUV7OH/ifF5Zsrfe+khRUOPzc7i4Mmz9D19bwzNzLUdCHk6qrvEx8tF5PDxra719Q+vg9+SU1ttWVOFl8uI9+Hx+iiq8rNp7pKWXFVfLd+cxfEIKe3NLeWNVBgt35sS8DGrbkMYoxLuoSI/5ZxVWUO0Lr4uv8DoNp/7A+15fto+Ccqf3zEeBHi0Nj/b59sOMfX4pn22uq7Z5bPY2np1nWbIrh1+8uY4fvLa6Xi+czmp2oOtmalp+M3u2TEvGj2+MqlOkIdeH+DfOHhTvIrhSWVUNf5mzg0ue/Lze+kn/2Rlcnrkhk9eX7QuGTl6ph/dTD/Bkyg6u/KszEmNtptSGS+3XfnvIGXq3dgjeSm8NeYHjeGv87DjorHfDqI3RvAv+dFM2Fz3xOeszClpbCJGI2vPYfadw3/VnB4d5ldaZ8kV442Vqel243PvBpnrbrv/7suCyp7b3jL/2L2fhpUV7+OPYs8LGgDn74brHBkK3JJFEcaWXD1IPcNeVI2Iydkyppzr4IRJrq/c5VUjbDxZz8anHxqUMklhcfyd+8sC+pE8aF+9idFlVNU6Yh37N/3RzdvBOc29uKZsbNHZ2S0qqV/3y0MdbeTJlBytbWUf+VMp27p+5Ofj6SKmHW6esIqckvF4/1D3vbOCWf65q1bkgOt372nqM2o+2rlad8vKi3TzaoN1F6nN9iNf65J5R/OCyU+JdjC7JU10TrDcH+P37G1kUaPybt+0w33l5Rb39vzxQEEyzvy/cFezuWPuB0FKvLUvjvbV1vW7eTz3A2rR8pq9Ib/J927JbN7xA7ZeDaM5xGvp940ipB28z195Ve2E9N38Xb6zKiHcxOrWECfELTz6GMeaEeBejSzIPzeXVCFUzjZm8eC8lnmoApoUEbklldbvKUV3jfDI0d7Pa1rvZ1lxjS89dXePj4icXcN+MzZHf0PD96mIoDSRMiANcddYJjD1HDZ1u9bv3vgwbdXHmhkxKPeHh/qcP6+rr75+5hf//6ipeWOAM7xsalDnFlUxevKdebxxfJ6qTqA407H62pel2HTd1McwpruTL/a1suI0g0nj7Ei6hQrx3j2Rev+NSlt93NVPvuCTexZE2+Nmb6xg+IYVDRU4Q3PvBJh7+pH6d6D3vbqg3WNd7a/ezel9d978D+eVc/vQC3lmTwWVPL+TZeZbtIQ2Ztd0j3ai9nz8z1mdGnB6wtbw1PnJLIofsNc8v5buvrGz3OV5eFP6AmYRLqBCvNezYvlxzzuB4F0PaoLZB9O3VGcEx1g8VOQ2VOSWVeGt8pDTTGylly0EOF3t48OO68L/vo81tngJvW3Y0e7I4ZWhYx93cfXZzdeJ+v5/XvtjX5N1rpbeGP324idumtL5Rt6EJH23h0qcW4KmuCdvW3moxaZ2EDHFxv9T0fGYGxn9Zte8I983YzGVPLeTPH25q5p2Rbc0q5s+N1DvfOT2V/LIqKr01/OyNVPbmllLj83PGA3N4e3UGWyKMs97eMVdqq0eiVbOzObOIp+bsCOsWmlNSyfdeWUFOSWXwXI3dQTfk9/sb/eCbu9X5IG1soDaJnYQO8Y2PXMuuJ29gx+PXs+aBa+jVPaEvN6GsScvnow11VSb/Doz98snGts81MmN9Jp9vD58padHOHKatSGNNWj4LduQwcfY2PNU1VPv8PPRJ5O5tP/7X2kbPU15VXW+WpVANM9HfyJ15YyIdtajCy02TnR5ADT9c3l69nw37C3ln9f6WnSDExNnbGHH/nIjbNBds55HQqXZM35707N6NPj2TGXx0b3495ox4F0ni7Odvrou4/qVFe4JdDwvLvdhDJc0eq+E4My8u3M0Sm8O5j8zj8c+2k1viobyq6aqF4JOuTVSoFFd6g42xkZ5wzWlQjsqQ7p61J9iaVcRlTztj1HuqfRRVNN8u0JKufdFqIk7PK6PYBUMwdEYJHeIN3XP16bx552VMuf3ieBdFOqFn5loAtmQVtahh7vKnFzJzQ2awauH5z3fxk2nOCIfTV6Zz6VML+F4zx5n5pVNlFHpje8VfFnLzP5z3Ld2Vy/kT51Ppdaot3lqVHnaMhrke2vumdmnhzpx6ddUbWvvYfwPRfvhozHNL+H+TVzS/o4TpUiHePbkbXz/rBK47bwjjvjI03sWRBHDvB5u4++0NvLRwd8TtOw+V8Nw8G7b+gY+3MHxCSljPG5/Pz8GiymAD79q0+k+xHimrorrGx8TZ24INvmvSGn/SdV9u5AeU2l0b0gG1KY2VFeoat9tq5KPzePKz5ieQ8fv97Doc/i2sqfaBeOtSIR7q+dsuAODno0fEuSSSCP72+a5Gt728uK6rXGM5UF5Vw/4j5Zz2QF0d9AMfb2Hy4gZDCPudht7pK9O576PNVFTV8MisbfX22ZBRGBx4LKWR/uc+v5+ikK6Wwyek8MDHW6j01jB8QgrvrW1hHXorc23jgULun9n6nkK3T11T7/WafUc4++H/tKhaCJzxcl5fngY4XVBnbcyKuN8nG7P45gtfsHBH/baTX729odH2gXjrsiHeq3sy6ZPG8eC4c9nwcExnlZMuaPiEFNam5TN/e+MzH3392cX1Xr+7JjxIp69M5/apTqNqjc9fb7iDWj+auoYbX1wWtj7UH97fyAWPzw87X0G587DV/SGThkQSrE5pZYqPf2017609wJQv9vHQJ02fI1Ro10lPdQ23vbqaSq+PfyzZGzZufXO++8oKfv/+xojbdhx07sIbHnNuIzNWvbd2P+dPnFfvQ6m8qpofvb4mqsM0NKXLhniogf16sui/r2LnE9drMC3pMLdOWRXVB42W78kLhm5rFTfSl7ulT4bW9k7x+53Q2pcbOUjv/WAjP3xtddj7Jv1nJ28302MmtMontDfMk5/VzTr1z6V7Gfv80haVGaCk0kteact/Zp9vP9zkuDYPfLyF4srqet+wltpclu/J468hwzp3JIV4wGkn9Kd3YL7OnU9cz62XDItziUSa91HIk6vR8Nv3NjS7T1ZhRbAao7K6hp9MS+Ubf1tKdoQnQWduyGLl3iPBLpANPyJGTVrUoolB8suqgne77bnDbenPy48zo9PP31zH3+bXVZWVeqrr9VyKVCsU65pz148n3hF690jm8ZtG8o2zB/O1M47j/Inzm3+TSBw0nHYv1LQVac2+f9HOw2QcKQ++Dh1Pvtb+I+VMW5nGuUOPJrOggv8NacS94i+Lgss/nZbKC7ddGHz92Kd1dfWbDhQyfEJK2LGzCiu4dUrdnXpRuRevz8fx/XuF7fvu2v2Mv/zUiNdRXOnl6N49GrvMoG7dIn/TWL47j8tGDKy3Lj/wLeefS+t+xj/511rWZRSEfWMP/dbQcIKU2g+fjupbrxBvRO8eyVw/cggAo888ntFnHk+/Xt3rPcot0pk99mnzvTHunB6533yob/59abCLY1Ps4ZJ6dfHTmhkSuFboBB219fSPfee8sN4q763dz1mDj4r4qP/5E+fz4d1XUOmtYfSZzmim98/cTJmnhhd/8F/B/UKDNKuwgl7du5FZUMGPpq7hritHkBwS8pHyfl0TXTN9Pn+9D4naU424fw6XDR/IB3df0eh720Mh3gJv3XV5cDlSiA/o06PFreQibtOSAI+2R2dvC1u3Nau4yck8arfte/pGXlq0JzjW/HO3XBDcJzSXR01yvkWcO/RoAKYuTwuOgppxpBxvE0MKlHqq6d+rLj6/2J3HHf9ayxmD+jPoqPBvEQ0nMI8m1Ym30ke/uoK7rzq93rpNj34zTqURkYZOe2BOcFhigOfm1/XT3x2hD3joCJcLdjiTmby3dn+T3UZHPjqv3us7AsMw7MkpDc5QFavhg3Un3koXnzqQi045lpsuPJFST3X9R5wDju/fkzKPM9vNmYP6s7uVXaBEJHpCJ/OI5ixBzX379lT7Gu2PHk0K8TZISkrinMBXsIZCGzxyiis5qncP+vRMDjbqpE8aF7GBR0TcZX1G01UkC3YcZkHIQ0PeGh89kqNf+aHqlCi56qzwqeEGHd2bPj2T41AaEelo2YWtGwrgx1MbH/myPXQnHiXTfnJpk/1Dhw7oHfHufew5g7j3WtPsE3Yi0rk0NkxxY1bta3yMm/ZQiEdJY/1Pa626/5rg8ojj+wUfWOjerRunD+rX6Pt+d82Z+Hx+Xl68h5m//hqHiyr51TvNP5AhIl2DQjwOFv33VVR4a/jdext5cNw5wXFc0vLKWL47l1OO68dJx/Qmq7AyWE3z+7Fn0iO5W8THm084qhd3jhrBX+fG5jFfEek8FOJxkJSURN+e3Xm9wWTOI47vx4jj6+7Kzxh0VHC5tkHktBP6s/OJ61mXXsDOQ8WcNfgoLjj5GAb06cF3LjyRLZmF/ObdL/n2BSfy8Zd1LeMnD+zDv39xBe+nHuCzzdlNDvvZlMV/GsPVzy1p03tFJPqSYjlGrjFmOJC2cOFChg3T2CQdrajcy1NztjPxO+fRt2f9z+sVe/L4yrABHN27B999ZQU3XzSMH331VPJKPfRI7sbuwyVcMnwgOSWVXPbUQrp3S6La5yd90jg2Hijks03ZDOjTA2+NjxcX7eG1H1/CWYP789aqjOCQn6HOHzaAzZnhc1WKdCVtGWAvMzOTa665BmCEtTa94XaFuLRIjc9Pjc9PzxbMU5pxpAxvjZ8T+vdi2so0Mo6U88JtF1JYXsXe3FI8Xh/TVqZHnO9y3PlDmfzDi/j9+18ya2M2Gx6+lg0ZBeSXVXHRqceQV1rFI7O2sutw5L73x/XryZGyto3sJ9LRXBHixpgXgK/iDOb1e2ttasi24SjEJYS3xke3kPEskptpIA6VXVjBr95ezzPfv4ABfXowZEDv4LbMgnL69exOZkEF5ww9irKqGjYeKKTSW8PDn2zlx1ecytfOOJ5fvLmen40eQVZBBYeLK/mf689mbVo+C3YcZtOBwrAPhOvOG8zBokp9q5A26YgQj2qduDHmKuBMa+0VxphzgH8BHTPqiySE9jz8cOIxfZj1mysjbht2bF8Aju3XE4ABfboFG4mvO29IcL91D40Ne+8Zg/rzw8tPCb4u9VSzbFcuNzSY0q+6xsf87Yc5ZWBfDhdX8o2zB+HzOx9EOSWVFJR56dm9W712jh0Hiymq8PLgx1vYm1vGU98dydhzBrMuvYB1GfnBQaN+8fXTyCvxcOeVI/jWS8v59ZjT+cpJA9iUWcShogrGnjuY5+ZZ0o+UM/Kkoynz1MRsEgLpXKJ6J26MeRzYb619PfB6J3CZtbY48Ho4uhMX6RB+v5+qGh+9ukd+wKz2//q+vDJOHNAHr8/H0b17sHJPHuedNACPt4Z+vbrTt2cySUlJeGt8dO+WRG6Jhxq/n2W78rj+K0PIKqjgs83Z5JdVccago7jlkmHsyC7ml2+v58Ebz8EPFFd4OfW4fuSVerjyjOO5dcoqLhk+kDX7jpBT4mHO70aTllfGzA2ZnHJcX04Z2JdKr48Rxzt/n3Jc33qTTPfu0Y1vn38iVTU+Ljz5GIYO6M0/luyFpCRGHNeXTzZmB/ft36s7pZ5q7rn6dOZsOdSpPtw6fXWKMeZVIMVaOyvwehlwl7V2V+D1cBTiIuICfr+f8irng62lyquq6Zncje5RfLw+ptUpEcRmGC8RkShLSkpqVYADYb3AYiHaY6dkA0NCXp8IRJ5uW0RE2i3aIT4f+D6AMeYiINtaGz6Ar4iIREVUQ9xauxJYb4xZCbwI3BPN44uISH1Rr8Cx1k6I9jFFRCQyjScuIuJiCnEREReLdX+YZIBDhw7F+LQiIu4UkpcRn+KKdYgPBRg/fnyMTysi4npDgb0NV8Y6xFOB0Th9x8OniRcRkYaScQI8NdLGmA5FKyIi0aWGTRERF3PF9GxNjVHuJsaYkcAs4AVr7cvGmJOBt3C+Lh0EbrfWeowx44E/AD7gVWvtVGNMD2A6cCpOVdRPrbX7jDEXAP/A+dlsttb+KuYX1gRjzDM4VWjdgb/gfCVM2Gs2xvTFKfNgoDfwBLCJBL7mWsaYPsBWnGteSAJfszFmDPAhsC2wagvwDHG45k5/Jx46RjlwF86ToK5jjOkHvITzj7vW48Bka+1oYA9wZ2C/R4CxwBjgj8aYgcAPgUJr7ZXAUziBCPB3nA+2UcAAY8wNsUovz48AAALrSURBVLieljDGXA2MDPzurscpa0JfM/BtYJ219irgVuB5Ev+aaz0E5AeWu8I1L7XWjgn8+S1xuuZOH+LANcAnANbaHcCxxpij41ukNvEAN+IMElZrDDA7sPwpzi/6ciDVWltkra0AVgCjcH4OHwf2XQCMMsb0xBmeMrXBMTqLL4BbAsuFQD8S/Jqttf+21j4TeHkykEmCXzOAMeZs4FwgJbBqDAl+zRGMIQ7X7IYQHwLkhrzOpf5Iia5gra0O/BJD9bPWegLLOTgt0A2vN2y9tdaH83VrCFAQYd9OwVpbY62tHZH/LmAOCX7NtQLjB72L8zW6K1zz34B7Q153hWs+1xgz2xiz3BhzLXG6ZjeEeEOJOkZ5Y9fVmvWd8mdjjLkJJ8R/02BTwl6ztfZrwHeAt6lfxoS7ZmPMj4FV1tq0RnZJuGsGdgOPATcBdwBTqd/GGLNrdkOIJ/IY5aWBxiCAk3CuteH1hq0PNIok4fwcjouwb6dhjLkOeBC4wVpbRIJfszHm4kCDNdbajTj/sUsS+ZqBccBNxpjVwM+Ah0nw37O1NitQdea31u4FDuFU9cb8mt0Q4ok8RvkC4ObA8s3AXGANcKkx5hhjTH+c+rNlOD+H2vrlbwOLrbVeYKcxpna24O8FjtEpGGMGAM8C37LW1jZ4JfQ1A18H/hvAGDMY6E+CX7O19jZr7aXW2q8Cr+P0TknoazbGjDfG/CmwPASnN9I04nDNrnjYxxgzCec/hw+4x1q7Kc5FajVjzMU49YbDAS+QBYzH6WbUG8jA6WbkNcZ8H/gzTj3ZS9bad4wxyTj/Qc7EaST9ibX2gDHmXGAKzgfyGmvtvXQSxphfABOBXSGr78C5jkS95j44X61PBvrgfOVeB7xJgl5zKGPMRCAdmEcCX7Mx5iicNo9jgJ44v+cvicM1uyLERUQkMjdUp4iISCMU4iIiLqYQFxFxMYW4iIiLKcRFRFxMIS4i4mIKcRERF1OIi4i42P8BdOdq4ATPYeYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " tenty. The first was peopee, most likely al chiflive nos, the CDC you’limext have buet in ther erplated in states. In addition thisp. crsoly clusingeven of coronavirus cause papee safered to the virus \n",
            "----\n",
            "iter 49900, loss 4.440099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKYRFBmPIIBa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}