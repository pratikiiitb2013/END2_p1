{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_S6_howToMakeEncoderDecoderClasses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP46xQPfypqGd6LN+bsbqja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikiiitb2013/END2_p1/blob/main/Session6/%20END2_S6_howToMakeEncoderDecoderClasses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "q9eqD4XaTjdr",
        "outputId": "549e6d33-2965-48ee-a6b0-949dda1d6790"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/tweets.csv\")\n",
        "# /content/tweets.csv\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0elSrpK0UXP7",
        "outputId": "1767a866-c3a0-4edd-fb36-712e5808f6df"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpDYgmu1e62_",
        "outputId": "659b19ae-e2f9-4b0f-e2ef-f1260cdd061d"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6zzR26We8P7"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq-uvjwXe-bm",
        "outputId": "6c20beb1-5fa2-4039-ad62-e50b4f09effb"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0f5a476ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9hwYkAOe_7S"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGRlPM02fBXq"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYx6DR-xfCmT"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRwFkrcffD3K"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-2VgwSfFA3"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieToAq6tfGbV",
        "outputId": "e8728683-5ddb-4e7e-d1f3-a2c792bd58a9"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJhZHAxZfIBo",
        "outputId": "24e47407-135b-4655-8250-4af28fc8f523"
      },
      "source": [
        "vars(train.examples[11])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'tweet': ['@sweetbay',\n",
              "  'That',\n",
              "  'was',\n",
              "  'Paul',\n",
              "  'Ryan',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  '.',\n",
              "  'How',\n",
              "  'did',\n",
              "  'Obama',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  'do',\n",
              "  '?',\n",
              "  'Getting',\n",
              "  'educated',\n",
              "  'on',\n",
              "  'the',\n",
              "  'facts',\n",
              "  'is',\n",
              "  'the',\n",
              "  'first',\n",
              "  'step',\n",
              "  'in',\n",
              "  'losing',\n",
              "  'that',\n",
              "  'liberalism',\n",
              "  '!']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX6j1GYpfJW2"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBFyi1wvfKuN",
        "outputId": "dc8632f6-cdb5-4760-bd87-bba635bd2832"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgQ_5qfvfMb_",
        "outputId": "d1a8ec71-86b2-4722-aafb-5a810f606fc7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlfS68_OfNzi"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsAmvAdfPp-",
        "outputId": "b36606f2-03e8-4be3-fd84-a767df0f6d35"
      },
      "source": [
        "next(iter(train_iterator))\n",
        "#len(train.examples[11].tweet)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 32]\n",
              "\t[.tweet]:('[torch.cuda.LongTensor of size 32x8 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urvHIc9dfWDq"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFoIERCpfh2o"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class encoder_part(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "    super().__init__() \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    # print('enc')\n",
        "    # print(text.shape)\n",
        "    embedded = self.embedding(text)\n",
        "    # print(embedded.shape)\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "    packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "    # print(hidden.shape, cell.shape)\n",
        "    # print(packed_output.data.shape)\n",
        "    return packed_output, hidden\n",
        "\n",
        "class decoder_part(nn.Module):\n",
        "\n",
        "  def __init__(self, input_to_decoder_size, decoder_hidden_size, no_times_decoder_cell_has_to_run):\n",
        "    super().__init__()\n",
        "    self.decoder_single_rnn_cell = nn.LSTMCell(input_to_decoder_size,decoder_hidden_size)\n",
        "    self.no_times_decoder_cell_has_to_run = no_times_decoder_cell_has_to_run\n",
        "    self.decoder_hidden_size = decoder_hidden_size\n",
        "\n",
        "  def forward(self, encoder_context_vector):\n",
        "    # print('dec')\n",
        "    # print(encoder_context_vector.shape)\n",
        "    encoder_context_vector = encoder_context_vector.squeeze(0)\n",
        "    # print(encoder_context_vector.shape)\n",
        "    hx = torch.zeros(encoder_context_vector.size(0),self.decoder_hidden_size).to(device)\n",
        "    cx = torch.zeros(encoder_context_vector.size(0),self.decoder_hidden_size).to(device)\n",
        "    otpt = []\n",
        "    for i in range(self.no_times_decoder_cell_has_to_run):\n",
        "      hx,cx = self.decoder_single_rnn_cell(encoder_context_vector,(hx,cx))\n",
        "      otpt.append(hx)\n",
        "      # print(i,hx.shape)\n",
        "    otpt = torch.stack(otpt,dim = 0)\n",
        "    return otpt, hx\n",
        "\n",
        "class combining_encoder_decoder(nn.Module):\n",
        "  \n",
        "  def __init__(self, encoder, decoder, hidden_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "  \n",
        "  def forward(self,src,src_len):\n",
        "    # print('combined')\n",
        "    # print(src.shape)\n",
        "    enc_packed_outputs, enc_hidden = self.encoder(src,src_len)\n",
        "    # print(enc_hidden.shape)\n",
        "    dec_otpt, dec_hidden = self.decoder(enc_hidden)\n",
        "    # print(dec_hidden.shape)\n",
        "    dense_outputs = self.fc(dec_hidden)\n",
        "    # print(dense_outputs.shape)\n",
        "    op = F.softmax(dense_outputs, dim=1)\n",
        "    # return dense_outputs\n",
        "    return op\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr0FnjzDfkue",
        "outputId": "45b6ee52-6281-4eb2-dc8d-6971c8bcc3c5"
      },
      "source": [
        "\n",
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "# model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)\n",
        "enc = encoder_part(size_of_vocab, embedding_dim, num_hidden_nodes, num_layers, dropout = dropout)\n",
        "dec = decoder_part(num_hidden_nodes,num_hidden_nodes,5)\n",
        "\n",
        "model = combining_encoder_decoder(enc,dec,num_hidden_nodes,num_output_nodes).to(device)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wki4EcEdfn_Y",
        "outputId": "6734e3e5-38a7-4fee-ab29-7ec9626c7d8f"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combining_encoder_decoder(\n",
            "  (encoder): encoder_part(\n",
            "    (embedding): Embedding(4651, 300)\n",
            "    (encoder): LSTM(300, 100, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (decoder): decoder_part(\n",
            "    (decoder_single_rnn_cell): LSTMCell(100, 100)\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,637,203 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nXhLKBFfpqq"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY8p83bkfrqT"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDAOPW-5ftVE"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h78655sfvDL",
        "outputId": "470020c1-236b-45f4-b2ca-474a315311e0"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.080 | Train Acc: 55.53%\n",
            "\t Val. Loss: 1.038 |  Val. Acc: 69.20% \n",
            "\n",
            "\tTrain Loss: 0.982 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.895 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.873 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.850 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.829 | Train Acc: 72.67%\n",
            "\t Val. Loss: 0.826 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 0.794 | Train Acc: 77.70%\n",
            "\t Val. Loss: 0.813 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.766 | Train Acc: 79.90%\n",
            "\t Val. Loss: 0.794 |  Val. Acc: 76.34% \n",
            "\n",
            "\tTrain Loss: 0.739 | Train Acc: 82.35%\n",
            "\t Val. Loss: 0.788 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.716 | Train Acc: 84.12%\n",
            "\t Val. Loss: 0.785 |  Val. Acc: 76.79% \n",
            "\n",
            "\tTrain Loss: 0.702 | Train Acc: 85.47%\n",
            "\t Val. Loss: 0.773 |  Val. Acc: 77.68% \n",
            "\n",
            "\tTrain Loss: 0.687 | Train Acc: 86.49%\n",
            "\t Val. Loss: 0.760 |  Val. Acc: 79.46% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQX7D-7_fwi1"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    enc = encoder_part(size_of_vocab, embedding_dim, num_hidden_nodes, num_layers, dropout = dropout).to(device)\n",
        "    encoder_packed_outputs, encoder_final_hidden = enc(tensor,length_tensor)\n",
        "    print('Encoder LSTM output vector after each word: ')\n",
        "    for i in range(encoder_packed_outputs.data.shape[0]):\n",
        "      print('after',i+1, 'word')\n",
        "      print(encoder_packed_outputs.data[i])\n",
        "    print()\n",
        "    print('Encoder LSTM final hidden vector')\n",
        "    print(encoder_final_hidden)\n",
        "    print()\n",
        "    dec = decoder_part(num_hidden_nodes,num_hidden_nodes,3).to(device)\n",
        "    decoder_outputs, decoder_final_hidden = dec(encoder_final_hidden)\n",
        "    print('Decoder LSTM output vector after each time step(total 3 time steps)')\n",
        "    for i in range(decoder_outputs.shape[0]):\n",
        "      print('after',i+1, 'time step')\n",
        "      print(decoder_outputs[i])\n",
        "    print()\n",
        "    print('Decoder LSTM final hidden vector')\n",
        "    print(decoder_final_hidden)\n",
        "    print()\n",
        "    print('Final vector after FC layer')\n",
        "    print(prediction)\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]\n",
        "\n",
        "\n",
        "# enc_packed_outputs, enc_hidden = self.encoder(src,src_len)\n",
        "# # print(enc_hidden.shape)\n",
        "# dec_otpt, dec_hidden = self.decoder(enc_hidden)\n",
        "# # print(dec_hidden.shape)\n",
        "# dense_outputs = self.fc(dec_hidden)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wZ_yqyZIfyyr",
        "outputId": "0c7c8d24-65af-4a48-9327-e99e646105c5"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder LSTM output vector after each word: \n",
            "after 1 word\n",
            "tensor([ 0.0352,  0.3577, -0.0248, -0.0633,  0.2264,  0.3074,  0.0270,  0.1468,\n",
            "        -0.0827, -0.1270,  0.4442,  0.1063, -0.1246,  0.0489, -0.1838,  0.0282,\n",
            "         0.2339, -0.0226,  0.2054, -0.3047,  0.0681, -0.0149, -0.1499,  0.0845,\n",
            "        -0.0093, -0.0070, -0.0747, -0.1579, -0.0337, -0.1937, -0.0428,  0.0438,\n",
            "        -0.1791,  0.0837,  0.2437, -0.0607, -0.0908,  0.1342, -0.0877, -0.1110,\n",
            "        -0.0668,  0.4461,  0.0657,  0.0326,  0.1159, -0.4542,  0.1636,  0.0097,\n",
            "        -0.1505,  0.1608, -0.0608,  0.2582, -0.3004, -0.0185,  0.0580,  0.2978,\n",
            "        -0.0135,  0.0025, -0.0142, -0.0347,  0.0399,  0.1452, -0.3567, -0.2266,\n",
            "        -0.0751,  0.1065, -0.3240, -0.0757, -0.0326, -0.0850, -0.1516,  0.0220,\n",
            "         0.1574,  0.2640,  0.0546,  0.0136,  0.0121,  0.2065,  0.3219, -0.0631,\n",
            "        -0.2596, -0.0485,  0.0212,  0.0215,  0.1327, -0.1218,  0.0588,  0.1193,\n",
            "         0.1561, -0.0640, -0.0593, -0.0570,  0.2283,  0.1248,  0.0092,  0.0135,\n",
            "         0.0438,  0.2413, -0.2988, -0.0127], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 2 word\n",
            "tensor([ 0.0271,  0.0897, -0.4397,  0.3015,  0.1272,  0.0975,  0.0480,  0.0570,\n",
            "        -0.3206, -0.6178,  0.1181,  0.0935, -0.0200, -0.1332,  0.1254,  0.0017,\n",
            "         0.0721, -0.2368,  0.0976, -0.1162, -0.0850,  0.0158, -0.0483, -0.0087,\n",
            "        -0.2550,  0.2342, -0.0020,  0.0064,  0.0940, -0.2158,  0.0030, -0.0096,\n",
            "         0.0351,  0.1341,  0.1148, -0.0597, -0.2366,  0.0617, -0.1522, -0.3816,\n",
            "        -0.1242,  0.2501,  0.2187,  0.0676,  0.2055, -0.1902,  0.2276,  0.1431,\n",
            "        -0.3203,  0.3471,  0.0678,  0.0933, -0.3311, -0.2122,  0.3154,  0.0651,\n",
            "        -0.2310, -0.1036, -0.4047,  0.0461, -0.1093, -0.0651,  0.0554, -0.1101,\n",
            "        -0.0407,  0.1460, -0.1708, -0.2052, -0.0364, -0.2241,  0.1530,  0.1933,\n",
            "        -0.1192,  0.0783,  0.2852, -0.0912,  0.0266,  0.1695, -0.0387, -0.1451,\n",
            "        -0.2553, -0.0460,  0.0930,  0.1095,  0.1056, -0.2347, -0.0200,  0.0036,\n",
            "        -0.0193, -0.3249, -0.0175,  0.3629, -0.0269,  0.2512, -0.0870,  0.1171,\n",
            "        -0.1658, -0.0759, -0.0443, -0.2937], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 3 word\n",
            "tensor([-0.0290, -0.1693, -0.0138,  0.3964, -0.0650,  0.3559,  0.0355,  0.2399,\n",
            "         0.0991, -0.0628,  0.3829, -0.0398, -0.1474, -0.0196, -0.1567,  0.0184,\n",
            "        -0.0504, -0.0532,  0.0224, -0.2083, -0.1552,  0.0857,  0.0346, -0.1404,\n",
            "         0.0478,  0.0650, -0.0294,  0.2212,  0.0860,  0.0191,  0.0263, -0.0268,\n",
            "         0.2300, -0.1133,  0.0457, -0.3119, -0.1167,  0.0910, -0.2826, -0.1164,\n",
            "        -0.1176,  0.2095, -0.1691, -0.0266, -0.0760, -0.0756,  0.0845,  0.2748,\n",
            "         0.2339,  0.2339, -0.3247,  0.2238, -0.1320,  0.0399,  0.1300, -0.0292,\n",
            "        -0.0767, -0.0761, -0.1496,  0.1989,  0.0154, -0.0643,  0.0550,  0.1537,\n",
            "        -0.0213,  0.0408, -0.3019, -0.0479,  0.0266,  0.0088,  0.2153,  0.2335,\n",
            "         0.0975,  0.0059, -0.0024, -0.2118, -0.0571, -0.3534, -0.5301, -0.3217,\n",
            "        -0.1715,  0.1008, -0.1564,  0.0981,  0.1030, -0.0653, -0.0899,  0.0819,\n",
            "         0.2289, -0.1611,  0.0973,  0.0040, -0.0685,  0.1589,  0.3048,  0.0356,\n",
            "        -0.4236, -0.1503, -0.0610, -0.1415], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 4 word\n",
            "tensor([-4.3101e-02, -3.3414e-01, -8.1001e-03,  3.6630e-02,  1.2777e-02,\n",
            "         1.4066e-01,  2.1299e-01,  2.7223e-01, -4.3955e-02, -5.1734e-01,\n",
            "         4.6758e-01,  2.4251e-02,  7.3298e-02, -1.5772e-01, -7.6483e-02,\n",
            "        -8.8565e-02,  6.4841e-02, -2.7028e-01,  2.7557e-01,  1.0646e-01,\n",
            "         3.2574e-01,  3.0706e-01,  1.5554e-01, -1.6020e-02, -2.6221e-01,\n",
            "        -2.5262e-02,  5.0554e-03,  9.2848e-02, -9.9515e-02, -6.0221e-02,\n",
            "        -1.0321e-03,  2.9735e-01,  7.4578e-02,  8.7291e-02,  4.6566e-01,\n",
            "        -1.6678e-01, -1.8527e-01,  3.5482e-01,  5.3842e-02, -1.1516e-01,\n",
            "         2.5743e-01,  9.9772e-02, -3.0738e-02, -4.9019e-02, -1.9133e-01,\n",
            "        -2.2931e-01, -1.3949e-01,  8.8119e-02, -2.1591e-01,  6.6949e-02,\n",
            "        -3.3230e-01,  2.1409e-01, -2.7012e-01,  3.1529e-01, -9.5404e-02,\n",
            "         1.4764e-02,  2.4672e-01, -3.5613e-01,  2.6063e-02,  5.1523e-04,\n",
            "         2.5139e-01,  1.5898e-01, -1.0300e-02,  2.1157e-02, -1.3457e-01,\n",
            "         1.3579e-01, -2.5394e-01, -1.5013e-02, -1.9720e-01,  2.3686e-01,\n",
            "         1.8172e-01,  1.2906e-03,  2.3152e-01, -2.3909e-03,  5.2861e-01,\n",
            "        -5.0788e-01,  8.2502e-02, -1.2910e-01,  1.3466e-01, -2.0695e-01,\n",
            "         3.6656e-01, -1.3051e-01,  2.0315e-01,  1.8876e-01,  2.3630e-01,\n",
            "        -4.6343e-02, -3.2552e-01,  7.7798e-02, -9.7986e-02, -3.3885e-01,\n",
            "         1.8484e-01,  2.0495e-02, -4.5831e-01,  2.2656e-01,  8.5372e-02,\n",
            "         1.9529e-02, -3.2614e-01, -5.9665e-02, -1.4059e-01, -2.3314e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 5 word\n",
            "tensor([ 0.0991, -0.2002,  0.2823, -0.3000,  0.1914,  0.1578,  0.1765,  0.2109,\n",
            "        -0.0050, -0.0989,  0.0764,  0.4628, -0.0493,  0.0127,  0.0623, -0.2592,\n",
            "        -0.0935,  0.0412,  0.1143, -0.0206,  0.3032,  0.4420,  0.1260, -0.1925,\n",
            "        -0.1909,  0.0058, -0.1799,  0.1739, -0.0071, -0.1892, -0.2322,  0.0325,\n",
            "        -0.0845,  0.1171,  0.1808, -0.0519, -0.0066,  0.0784, -0.1339, -0.1810,\n",
            "         0.1066,  0.0086, -0.1321,  0.1647,  0.0124,  0.1227, -0.0800,  0.4122,\n",
            "        -0.1244,  0.0428, -0.2775,  0.1615, -0.0672, -0.0007, -0.0035, -0.0996,\n",
            "        -0.0850, -0.4317,  0.0558, -0.3553,  0.3897,  0.3784, -0.1021, -0.0272,\n",
            "        -0.1812,  0.2324,  0.1062,  0.2416, -0.4706,  0.3157,  0.1326,  0.2014,\n",
            "         0.2460, -0.0197,  0.2940, -0.4310, -0.1305,  0.1075,  0.2646,  0.4616,\n",
            "         0.0679, -0.2247,  0.3159,  0.3476,  0.4546, -0.2686, -0.1957,  0.0214,\n",
            "        -0.0502, -0.1724,  0.0874, -0.1768, -0.3488,  0.5403, -0.0320,  0.0938,\n",
            "        -0.0719,  0.0214,  0.0301, -0.0063], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 6 word\n",
            "tensor([ 0.0346, -0.2469, -0.0724,  0.0601,  0.0791,  0.1135,  0.2917, -0.0101,\n",
            "        -0.1910,  0.2751,  0.1650,  0.0452, -0.3284, -0.1256, -0.0979, -0.1924,\n",
            "         0.0561,  0.0858,  0.0089,  0.2377, -0.0209,  0.2522, -0.0514,  0.1592,\n",
            "        -0.2172, -0.1085, -0.3977, -0.0895, -0.0259, -0.1336, -0.2658,  0.0977,\n",
            "        -0.1954,  0.1448,  0.3330,  0.0130, -0.0908,  0.2381, -0.0673, -0.0329,\n",
            "        -0.0161, -0.2901,  0.0037, -0.1102, -0.1172, -0.0303, -0.1886,  0.1069,\n",
            "         0.0076,  0.0744, -0.2916, -0.0392,  0.1253,  0.1369,  0.3237,  0.3120,\n",
            "         0.0081, -0.3014,  0.0480, -0.1223,  0.0061,  0.1323, -0.1277, -0.0235,\n",
            "        -0.0361, -0.0371,  0.1453,  0.0813, -0.0680,  0.0665,  0.3118, -0.1061,\n",
            "        -0.0019,  0.1481, -0.0651, -0.2795,  0.0994,  0.1137,  0.1964,  0.0570,\n",
            "         0.0700, -0.1347,  0.0960,  0.0712,  0.2257, -0.1551, -0.3187,  0.4156,\n",
            "        -0.1341, -0.1672,  0.2464, -0.3182, -0.2109,  0.5191,  0.1858, -0.2055,\n",
            "         0.0654,  0.1538, -0.3369,  0.2147], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 7 word\n",
            "tensor([-0.0313,  0.0193, -0.3824,  0.0290, -0.2234,  0.0557,  0.3783, -0.0507,\n",
            "         0.0014,  0.2498,  0.1389,  0.0625,  0.1491, -0.2306,  0.0289, -0.1628,\n",
            "        -0.3520,  0.0048, -0.0985,  0.1495,  0.2268,  0.0535, -0.2048,  0.2112,\n",
            "        -0.1386,  0.0156, -0.1803, -0.0191,  0.2284, -0.2974,  0.1232, -0.1997,\n",
            "        -0.0656, -0.0144,  0.5405, -0.0306, -0.0887, -0.1480,  0.0620,  0.0176,\n",
            "        -0.0608, -0.1882, -0.2486,  0.0390,  0.3291, -0.0546,  0.1442,  0.2252,\n",
            "         0.0578,  0.0018, -0.2889, -0.1732, -0.1165,  0.0553,  0.2607,  0.3686,\n",
            "         0.2864, -0.1932,  0.3055, -0.1295, -0.3383,  0.3940, -0.0483,  0.0612,\n",
            "        -0.0943, -0.0347, -0.1307,  0.1204, -0.2764, -0.0836,  0.0235, -0.0929,\n",
            "        -0.1488,  0.4088,  0.0166, -0.0599, -0.0120,  0.0461,  0.4205, -0.0658,\n",
            "         0.1466, -0.0955,  0.1841, -0.0128,  0.0566,  0.1859, -0.3164,  0.3739,\n",
            "         0.1270,  0.0333,  0.0418, -0.1163, -0.2371,  0.3297,  0.2028,  0.0191,\n",
            "        -0.0492,  0.3362, -0.1559,  0.0878], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 8 word\n",
            "tensor([ 0.0869,  0.0329, -0.2466, -0.1786, -0.0289,  0.1417,  0.2314,  0.2992,\n",
            "        -0.3206,  0.3490, -0.1931,  0.2617,  0.1712, -0.1285,  0.3831, -0.2468,\n",
            "        -0.0070,  0.0452, -0.6360,  0.2838,  0.0962, -0.1699, -0.0718,  0.2330,\n",
            "        -0.3700,  0.0234, -0.0661,  0.0311, -0.3256, -0.0057, -0.2554, -0.0910,\n",
            "        -0.5202,  0.1808,  0.2211,  0.0271, -0.0626, -0.2354,  0.1069, -0.0975,\n",
            "        -0.0391, -0.4637, -0.0242,  0.4513,  0.0439, -0.1675, -0.0691,  0.1609,\n",
            "         0.1724, -0.1073, -0.1616, -0.1484, -0.0419,  0.0165, -0.1595,  0.1354,\n",
            "         0.0784,  0.3346, -0.0041,  0.0884, -0.2317,  0.0207,  0.0031,  0.2499,\n",
            "         0.1895, -0.2201, -0.3220,  0.2098, -0.4564,  0.0425, -0.0632, -0.0766,\n",
            "         0.0738,  0.1033,  0.0413,  0.0902, -0.4828,  0.5234,  0.4543, -0.0642,\n",
            "         0.4067,  0.1434,  0.2364, -0.0860,  0.0407,  0.2004, -0.3704,  0.3547,\n",
            "        -0.0084,  0.0586,  0.0417,  0.3416, -0.1642,  0.0373, -0.0089, -0.1025,\n",
            "        -0.0326,  0.2049, -0.1181, -0.0568], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 9 word\n",
            "tensor([ 0.1551, -0.0276, -0.0482, -0.0408, -0.3897,  0.0202,  0.5639, -0.0534,\n",
            "        -0.1808,  0.3752, -0.1152,  0.1806,  0.2749, -0.0478,  0.0070, -0.1935,\n",
            "        -0.3590, -0.1674, -0.1929,  0.1222,  0.2012, -0.0123,  0.2250, -0.1699,\n",
            "        -0.1075, -0.1078, -0.0496, -0.0826,  0.0871, -0.2134, -0.0327, -0.1869,\n",
            "        -0.0845,  0.0818, -0.0534,  0.2299, -0.1578, -0.3834,  0.0014,  0.1700,\n",
            "         0.2884, -0.0810,  0.4693,  0.4767,  0.2693,  0.0657, -0.0411, -0.1299,\n",
            "         0.1433,  0.3822, -0.2528, -0.1086,  0.0846, -0.0606, -0.0251,  0.0202,\n",
            "         0.1245,  0.0982,  0.0900,  0.0996, -0.0135, -0.0176, -0.1855,  0.2074,\n",
            "         0.2343,  0.0394, -0.1377,  0.0894, -0.1625,  0.0776, -0.1503, -0.2066,\n",
            "         0.0932, -0.1272,  0.1224, -0.1236, -0.1634, -0.0057,  0.0506, -0.1916,\n",
            "         0.1725,  0.1566,  0.0804, -0.3141,  0.5318,  0.0944,  0.0478,  0.3617,\n",
            "         0.2344, -0.0341, -0.1673,  0.0555, -0.5315,  0.2075, -0.1241,  0.1005,\n",
            "         0.0810,  0.3194, -0.1273,  0.0111], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 10 word\n",
            "tensor([ 0.0560,  0.0202, -0.0999,  0.0332,  0.1089, -0.0285,  0.3247, -0.0739,\n",
            "        -0.5843,  0.0445, -0.2689,  0.0250,  0.2557,  0.1084, -0.0621, -0.4555,\n",
            "        -0.0920, -0.6120, -0.5303,  0.2578,  0.1413, -0.2544,  0.0834, -0.0812,\n",
            "        -0.4364, -0.3489, -0.1343,  0.3019, -0.0418, -0.2471, -0.1312,  0.1329,\n",
            "        -0.0458,  0.1787, -0.0685,  0.0572, -0.1090, -0.2236, -0.0756, -0.1124,\n",
            "        -0.2127, -0.0694, -0.0073,  0.0151,  0.0052, -0.2822, -0.2527, -0.0185,\n",
            "        -0.0210, -0.0123, -0.1460, -0.1961,  0.1332,  0.2907, -0.4952,  0.1303,\n",
            "         0.0093, -0.1008,  0.2066, -0.0919,  0.0334,  0.0960, -0.2329,  0.0248,\n",
            "         0.3555, -0.2164, -0.0925,  0.0660, -0.1805, -0.0362, -0.0318,  0.0714,\n",
            "         0.0644, -0.0042,  0.2878,  0.0214, -0.0262, -0.0173, -0.1475, -0.2342,\n",
            "        -0.0681, -0.1526, -0.0837, -0.1633,  0.3590,  0.0949,  0.4397,  0.0909,\n",
            "         0.1379, -0.0354, -0.2297, -0.1049, -0.0625,  0.2051, -0.0290, -0.1537,\n",
            "         0.2686,  0.2872,  0.2793, -0.0133], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 11 word\n",
            "tensor([-0.1296,  0.1215, -0.0498,  0.0635, -0.0614,  0.2097,  0.3480, -0.0427,\n",
            "        -0.1386,  0.0986, -0.3614, -0.2776,  0.1627, -0.0404, -0.3191,  0.0303,\n",
            "        -0.1169, -0.0027,  0.0331,  0.2502, -0.0100, -0.1179,  0.0149, -0.3380,\n",
            "        -0.4096, -0.0689, -0.1253,  0.0537, -0.2353,  0.1644,  0.1443,  0.0103,\n",
            "        -0.0778,  0.0264, -0.2340, -0.2877, -0.0568, -0.1072,  0.0486, -0.1338,\n",
            "        -0.0608,  0.1158, -0.0306, -0.0335, -0.0705,  0.0295, -0.1282,  0.1908,\n",
            "         0.0495,  0.0362, -0.0808,  0.0361, -0.1450, -0.0368, -0.2496, -0.1175,\n",
            "         0.2289, -0.0683,  0.0676,  0.0418,  0.4496, -0.0261, -0.1035, -0.1809,\n",
            "         0.1433, -0.0510,  0.1129,  0.2988,  0.1748, -0.1796, -0.0579, -0.0551,\n",
            "         0.0130, -0.0932, -0.1617,  0.0413, -0.3023,  0.1409,  0.0134, -0.0047,\n",
            "         0.1641,  0.0690, -0.2099,  0.0584,  0.2025,  0.1258,  0.3716,  0.2527,\n",
            "         0.2645,  0.0178, -0.0678,  0.1537, -0.0468, -0.1837,  0.0309,  0.1051,\n",
            "        -0.2861,  0.0840,  0.0334,  0.1954], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 12 word\n",
            "tensor([-6.6599e-04,  5.1372e-01, -3.2185e-02, -1.1038e-03,  7.1155e-02,\n",
            "         2.7703e-01,  5.4158e-01, -4.9186e-01,  1.2192e-01,  1.1837e-01,\n",
            "        -1.6899e-01, -1.2185e-01,  2.3675e-01, -1.8291e-02,  4.0799e-02,\n",
            "        -1.0250e-01,  1.7821e-01, -1.6251e-01,  1.1633e-02,  6.1851e-02,\n",
            "        -7.0099e-03, -1.5697e-02,  1.2911e-01,  1.0467e-02, -5.6925e-02,\n",
            "        -3.2488e-02, -1.8763e-03, -2.8934e-02,  5.9122e-02, -7.4020e-05,\n",
            "        -2.2726e-01,  7.4636e-02,  8.0786e-02,  2.0216e-02, -2.1516e-01,\n",
            "        -6.7604e-02,  6.9275e-02,  2.4529e-01, -2.9456e-01, -1.1154e-01,\n",
            "        -2.1885e-01, -3.6828e-01, -3.4772e-02, -1.6359e-01, -7.6902e-02,\n",
            "         2.2632e-01, -5.1831e-02,  2.1255e-01, -4.3371e-01,  1.1739e-01,\n",
            "        -2.0774e-01,  1.4525e-02,  1.5337e-01, -1.4942e-01, -1.7923e-01,\n",
            "         1.4455e-01,  2.5537e-02, -1.0373e-01,  2.1372e-01,  4.3239e-01,\n",
            "        -4.7189e-02,  1.2267e-01, -2.0002e-01, -4.1124e-02,  1.2949e-01,\n",
            "        -2.9547e-01, -3.1041e-02,  2.2377e-01, -4.2869e-01, -1.5720e-01,\n",
            "        -2.2334e-02, -4.3113e-02, -2.2584e-01, -3.0195e-01, -1.2968e-01,\n",
            "         1.0186e-01,  1.3400e-01,  3.4499e-01, -1.3198e-01,  1.9633e-02,\n",
            "         2.0723e-01, -6.9133e-02, -1.3269e-01,  1.8344e-01,  1.0446e-02,\n",
            "         3.0338e-02,  5.5119e-02,  2.8127e-01,  3.3731e-03,  1.0338e-01,\n",
            "        -8.7334e-04, -4.7285e-02, -1.0020e-01,  2.5491e-01,  8.8303e-04,\n",
            "        -1.7952e-01, -5.7943e-03, -1.3116e-01,  1.3024e-01,  7.1871e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 13 word\n",
            "tensor([-0.1732,  0.5063, -0.0954,  0.1181,  0.2760,  0.0947,  0.2658, -0.0638,\n",
            "        -0.0390,  0.3028,  0.0758, -0.3765, -0.1804, -0.1350, -0.0375,  0.1164,\n",
            "         0.3050, -0.2091, -0.3451,  0.0497, -0.2521, -0.1451,  0.4108, -0.0861,\n",
            "        -0.3156, -0.0614, -0.0774,  0.0917, -0.1160,  0.0334,  0.0162,  0.2077,\n",
            "         0.0167, -0.1218,  0.0156,  0.0295,  0.0787, -0.1179, -0.2965, -0.0936,\n",
            "        -0.0191,  0.0093,  0.1337, -0.2411, -0.1473,  0.2637, -0.1878,  0.0726,\n",
            "        -0.1222, -0.1022, -0.1048, -0.1428, -0.1812, -0.1079, -0.0433,  0.0014,\n",
            "         0.3739, -0.2992,  0.0633,  0.1048,  0.0321,  0.1048, -0.2116, -0.2534,\n",
            "         0.0097, -0.3090,  0.2569,  0.0130, -0.2720, -0.2305, -0.0396, -0.0587,\n",
            "         0.0551,  0.2411, -0.0216,  0.1377,  0.0234, -0.1612,  0.0777,  0.2613,\n",
            "         0.5999,  0.0208, -0.0217,  0.0803,  0.0892,  0.1217,  0.0114,  0.3168,\n",
            "        -0.0366, -0.0068,  0.2041,  0.0365, -0.0427,  0.1979, -0.1491,  0.0234,\n",
            "        -0.0527, -0.1064,  0.0709, -0.4667], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 14 word\n",
            "tensor([-6.0066e-02,  1.0415e-01, -1.7449e-01, -1.1660e-01,  9.6018e-02,\n",
            "         1.3082e-02, -2.4781e-04, -5.5050e-02,  1.0346e-01, -1.1667e-02,\n",
            "        -1.1124e-01, -1.9660e-01, -5.2961e-02, -9.2214e-02, -9.8571e-02,\n",
            "        -3.1877e-02,  1.1397e-01,  1.2675e-01, -8.2887e-02, -7.1443e-02,\n",
            "         3.3153e-01, -1.8519e-01, -2.9158e-02, -4.0732e-02, -2.1907e-01,\n",
            "         1.3830e-01, -2.2529e-03,  8.7721e-02,  3.1589e-01, -1.0049e-01,\n",
            "        -5.8264e-02,  1.3279e-01,  3.4492e-01,  1.0077e-01, -4.9915e-02,\n",
            "         1.2208e-01,  6.4381e-02, -2.6548e-02,  1.8162e-01, -1.7925e-01,\n",
            "        -2.8428e-02,  1.0773e-02,  6.8834e-02,  5.3613e-02,  1.2420e-01,\n",
            "         1.8513e-01, -1.3850e-01,  1.4774e-01,  1.2973e-01, -5.9471e-02,\n",
            "        -1.1010e-01,  9.5091e-02, -2.4286e-01, -4.2621e-01,  7.0994e-02,\n",
            "         1.0883e-01,  4.2628e-01, -5.0873e-02,  1.4699e-01, -9.5774e-02,\n",
            "        -2.3034e-01,  3.6239e-01, -9.4033e-03, -2.1767e-02, -1.4091e-01,\n",
            "        -1.7544e-01,  3.0376e-01,  4.9187e-02, -3.0039e-02,  3.3568e-02,\n",
            "        -1.2873e-01, -2.6257e-01, -2.7730e-02,  6.9134e-02,  6.4441e-02,\n",
            "         4.2942e-01, -1.7272e-02,  4.6662e-02,  7.1871e-02, -1.7494e-01,\n",
            "         3.5732e-01,  2.0056e-01, -2.4218e-02,  4.5893e-01,  1.6686e-01,\n",
            "         7.4251e-02,  2.7244e-02, -1.4886e-01,  9.3594e-02, -1.5694e-01,\n",
            "         9.8239e-02,  1.4843e-01,  1.9773e-01, -5.1891e-02,  2.0328e-01,\n",
            "         3.0521e-02,  1.8091e-01,  3.6510e-02, -2.2008e-01,  1.9963e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 15 word\n",
            "tensor([ 0.2799,  0.2299,  0.1375, -0.3331,  0.4011,  0.0572, -0.4193, -0.1334,\n",
            "         0.0790,  0.3395, -0.3423, -0.0725, -0.0357, -0.0425,  0.1886, -0.0328,\n",
            "         0.0921,  0.0456,  0.0533, -0.1182,  0.4218, -0.2663,  0.0295, -0.1282,\n",
            "        -0.2745, -0.0884,  0.0778,  0.2013, -0.1585,  0.0006, -0.0819, -0.0060,\n",
            "        -0.0472,  0.3737, -0.2035,  0.4826,  0.2833,  0.1569, -0.1082,  0.1307,\n",
            "         0.0995, -0.0389, -0.2041,  0.0176,  0.0808,  0.0331, -0.3668,  0.5256,\n",
            "         0.1528, -0.1302, -0.0509,  0.0918,  0.1020, -0.2618, -0.0219, -0.1741,\n",
            "         0.1263,  0.0531, -0.0331, -0.2481, -0.3678,  0.4858,  0.0019, -0.0748,\n",
            "        -0.5065, -0.1847,  0.4294,  0.0153, -0.1433,  0.4138,  0.0976, -0.2329,\n",
            "         0.0895,  0.1692,  0.0729, -0.2035, -0.0199,  0.5785,  0.1182,  0.1141,\n",
            "         0.1885,  0.2633,  0.0712,  0.1053, -0.0173,  0.1967,  0.0874, -0.1141,\n",
            "         0.0179, -0.2656, -0.1868,  0.2733,  0.2007, -0.1986,  0.1335,  0.1008,\n",
            "         0.3192,  0.2889, -0.0690,  0.3785], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Encoder LSTM final hidden vector\n",
            "tensor([[[ 0.2799,  0.2299,  0.1375, -0.3331,  0.4011,  0.0572, -0.4193,\n",
            "          -0.1334,  0.0790,  0.3395, -0.3423, -0.0725, -0.0357, -0.0425,\n",
            "           0.1886, -0.0328,  0.0921,  0.0456,  0.0533, -0.1182,  0.4218,\n",
            "          -0.2663,  0.0295, -0.1282, -0.2745, -0.0884,  0.0778,  0.2013,\n",
            "          -0.1585,  0.0006, -0.0819, -0.0060, -0.0472,  0.3737, -0.2035,\n",
            "           0.4826,  0.2833,  0.1569, -0.1082,  0.1307,  0.0995, -0.0389,\n",
            "          -0.2041,  0.0176,  0.0808,  0.0331, -0.3668,  0.5256,  0.1528,\n",
            "          -0.1302, -0.0509,  0.0918,  0.1020, -0.2618, -0.0219, -0.1741,\n",
            "           0.1263,  0.0531, -0.0331, -0.2481, -0.3678,  0.4858,  0.0019,\n",
            "          -0.0748, -0.5065, -0.1847,  0.4294,  0.0153, -0.1433,  0.4138,\n",
            "           0.0976, -0.2329,  0.0895,  0.1692,  0.0729, -0.2035, -0.0199,\n",
            "           0.5785,  0.1182,  0.1141,  0.1885,  0.2633,  0.0712,  0.1053,\n",
            "          -0.0173,  0.1967,  0.0874, -0.1141,  0.0179, -0.2656, -0.1868,\n",
            "           0.2733,  0.2007, -0.1986,  0.1335,  0.1008,  0.3192,  0.2889,\n",
            "          -0.0690,  0.3785]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "Decoder LSTM output vector after each time step(total 3 time steps)\n",
            "after 1 time step\n",
            "tensor([[-0.0093, -0.0139,  0.0085,  0.0153,  0.0330,  0.0076, -0.0355, -0.0045,\n",
            "         -0.0011, -0.0417, -0.0141,  0.0376, -0.0024, -0.0550,  0.0159, -0.0157,\n",
            "         -0.0155, -0.0041,  0.0293, -0.0296, -0.0181, -0.0284,  0.0805,  0.0108,\n",
            "         -0.0174,  0.0457, -0.0368,  0.0145,  0.0249,  0.0251, -0.0300, -0.0145,\n",
            "          0.0470, -0.0397, -0.0015, -0.0263, -0.0189,  0.0024, -0.0234,  0.0378,\n",
            "          0.0859, -0.0388, -0.0094, -0.0226, -0.0189,  0.0072,  0.0216,  0.0764,\n",
            "          0.0115, -0.0416,  0.0360, -0.0347,  0.0169, -0.0424, -0.0419, -0.0110,\n",
            "         -0.0208,  0.0275, -0.0850,  0.0463,  0.0590, -0.0028, -0.0110, -0.0076,\n",
            "          0.0103, -0.0492, -0.0152, -0.0498,  0.0364,  0.0582,  0.0395, -0.0278,\n",
            "         -0.0106, -0.0030,  0.0524,  0.0312, -0.0370, -0.0458,  0.0214,  0.0140,\n",
            "          0.0397, -0.0050, -0.0137, -0.0172, -0.0404,  0.0267, -0.0697,  0.0297,\n",
            "          0.0420,  0.0013, -0.0198,  0.0287, -0.0186, -0.0177,  0.0809,  0.0613,\n",
            "          0.0385,  0.0309, -0.0338,  0.0241]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 2 time step\n",
            "tensor([[-0.0079, -0.0195,  0.0213,  0.0202,  0.0421,  0.0073, -0.0554, -0.0035,\n",
            "          0.0023, -0.0668, -0.0175,  0.0525, -0.0090, -0.0797,  0.0290, -0.0250,\n",
            "         -0.0248, -0.0058,  0.0358, -0.0457, -0.0176, -0.0460,  0.1181,  0.0169,\n",
            "         -0.0281,  0.0631, -0.0521,  0.0245,  0.0341,  0.0281, -0.0489, -0.0234,\n",
            "          0.0706, -0.0613,  0.0036, -0.0450, -0.0340,  0.0016, -0.0339,  0.0620,\n",
            "          0.1268, -0.0612, -0.0153, -0.0318, -0.0399,  0.0107,  0.0309,  0.1102,\n",
            "          0.0209, -0.0574,  0.0549, -0.0479,  0.0338, -0.0586, -0.0612, -0.0307,\n",
            "         -0.0200,  0.0418, -0.1222,  0.0620,  0.0870, -0.0067, -0.0113, -0.0115,\n",
            "          0.0252, -0.0839, -0.0162, -0.0781,  0.0612,  0.0899,  0.0655, -0.0434,\n",
            "         -0.0118,  0.0023,  0.0676,  0.0582, -0.0607, -0.0677,  0.0340,  0.0197,\n",
            "          0.0603, -0.0080, -0.0246, -0.0267, -0.0551,  0.0261, -0.0909,  0.0534,\n",
            "          0.0620,  0.0010, -0.0286,  0.0399, -0.0259, -0.0238,  0.1193,  0.0875,\n",
            "          0.0558,  0.0467, -0.0567,  0.0320]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 3 time step\n",
            "tensor([[-0.0042, -0.0226,  0.0315,  0.0216,  0.0436,  0.0053, -0.0675, -0.0019,\n",
            "          0.0051, -0.0806, -0.0178,  0.0593, -0.0138, -0.0911,  0.0362, -0.0309,\n",
            "         -0.0308, -0.0054,  0.0335, -0.0539, -0.0136, -0.0563,  0.1359,  0.0192,\n",
            "         -0.0347,  0.0689, -0.0593,  0.0309,  0.0381,  0.0240, -0.0598, -0.0283,\n",
            "          0.0827, -0.0738,  0.0090, -0.0564, -0.0448,  0.0007, -0.0385,  0.0765,\n",
            "          0.1475, -0.0731, -0.0188, -0.0345, -0.0563,  0.0133,  0.0341,  0.1252,\n",
            "          0.0265, -0.0633,  0.0634, -0.0529,  0.0467, -0.0652, -0.0696, -0.0478,\n",
            "         -0.0149,  0.0504, -0.1393,  0.0671,  0.1011, -0.0095, -0.0090, -0.0145,\n",
            "          0.0363, -0.1053, -0.0145, -0.0929,  0.0774,  0.1076,  0.0817, -0.0518,\n",
            "         -0.0099,  0.0082,  0.0697,  0.0780, -0.0751, -0.0777,  0.0410,  0.0226,\n",
            "          0.0702, -0.0099, -0.0319, -0.0322, -0.0594,  0.0191, -0.0944,  0.0693,\n",
            "          0.0716,  0.0012, -0.0322,  0.0439, -0.0296, -0.0261,  0.1377,  0.0993,\n",
            "          0.0642,  0.0548, -0.0708,  0.0334]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "\n",
            "Decoder LSTM final hidden vector\n",
            "tensor([[-0.0042, -0.0226,  0.0315,  0.0216,  0.0436,  0.0053, -0.0675, -0.0019,\n",
            "          0.0051, -0.0806, -0.0178,  0.0593, -0.0138, -0.0911,  0.0362, -0.0309,\n",
            "         -0.0308, -0.0054,  0.0335, -0.0539, -0.0136, -0.0563,  0.1359,  0.0192,\n",
            "         -0.0347,  0.0689, -0.0593,  0.0309,  0.0381,  0.0240, -0.0598, -0.0283,\n",
            "          0.0827, -0.0738,  0.0090, -0.0564, -0.0448,  0.0007, -0.0385,  0.0765,\n",
            "          0.1475, -0.0731, -0.0188, -0.0345, -0.0563,  0.0133,  0.0341,  0.1252,\n",
            "          0.0265, -0.0633,  0.0634, -0.0529,  0.0467, -0.0652, -0.0696, -0.0478,\n",
            "         -0.0149,  0.0504, -0.1393,  0.0671,  0.1011, -0.0095, -0.0090, -0.0145,\n",
            "          0.0363, -0.1053, -0.0145, -0.0929,  0.0774,  0.1076,  0.0817, -0.0518,\n",
            "         -0.0099,  0.0082,  0.0697,  0.0780, -0.0751, -0.0777,  0.0410,  0.0226,\n",
            "          0.0702, -0.0099, -0.0319, -0.0322, -0.0594,  0.0191, -0.0944,  0.0693,\n",
            "          0.0716,  0.0012, -0.0322,  0.0439, -0.0296, -0.0261,  0.1377,  0.0993,\n",
            "          0.0642,  0.0548, -0.0708,  0.0334]], device='cuda:0',\n",
            "       grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "\n",
            "Final vector after FC layer\n",
            "tensor([[9.9084e-01, 8.6920e-03, 4.7107e-04]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JasIrTqHf0lG",
        "outputId": "d1be08b1-8c5f-4015-c6cf-fad3da6bab41"
      },
      "source": [
        "classify_tweet(\"RT @Talkmaster: Oh now I get it. Obama was talking in shorthand and we were just too dumb to understand how smart he really is.  Gagme.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder LSTM output vector after each word: \n",
            "after 1 word\n",
            "tensor([-0.1336, -0.1873, -0.0797, -0.1048, -0.0683, -0.4130, -0.1124, -0.1877,\n",
            "         0.1896,  0.0704,  0.1121, -0.0431,  0.1759, -0.0422, -0.0012, -0.1328,\n",
            "        -0.3805, -0.1145,  0.1671, -0.3878, -0.2770,  0.0176,  0.1299,  0.0374,\n",
            "        -0.1623, -0.2797,  0.0472, -0.0976, -0.2012,  0.1882,  0.0119, -0.0842,\n",
            "        -0.3260,  0.0758,  0.3246,  0.1177, -0.0512,  0.2329,  0.0161,  0.0095,\n",
            "         0.4957, -0.2579, -0.1149,  0.1888, -0.0805,  0.0674, -0.2215,  0.3768,\n",
            "        -0.1377, -0.1988,  0.0228, -0.0469,  0.2688,  0.0443,  0.1323, -0.0745,\n",
            "        -0.2560,  0.1402, -0.0408, -0.1374, -0.0790, -0.1629, -0.3620, -0.0447,\n",
            "         0.1269, -0.0353, -0.0540, -0.4123, -0.1184,  0.2504, -0.0104,  0.1671,\n",
            "         0.0325,  0.2604,  0.0101,  0.2449,  0.2173,  0.1621, -0.0966,  0.0006,\n",
            "         0.0543, -0.1400,  0.0901, -0.0347, -0.3698, -0.0932,  0.1912, -0.0879,\n",
            "         0.3361, -0.0133, -0.0915,  0.0136,  0.3797,  0.1884, -0.0692, -0.1518,\n",
            "         0.2634, -0.2284,  0.1748, -0.1890], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 2 word\n",
            "tensor([ 0.0632,  0.0894,  0.1834, -0.2437, -0.0506,  0.0352,  0.0741,  0.4770,\n",
            "         0.3605,  0.0409,  0.0828, -0.2031,  0.0370,  0.0085,  0.3504, -0.0176,\n",
            "         0.0230, -0.1836, -0.0760, -0.5343, -0.1028,  0.1266,  0.1156, -0.0126,\n",
            "        -0.0727, -0.0633, -0.0016, -0.0183, -0.3795,  0.3307,  0.0903,  0.0866,\n",
            "        -0.2682, -0.0943, -0.0343,  0.2535, -0.0539,  0.0095, -0.0894,  0.0446,\n",
            "         0.5526, -0.3234, -0.0333,  0.2024, -0.0363,  0.1857, -0.2099,  0.0760,\n",
            "         0.0324,  0.1247,  0.1000, -0.3078,  0.3415, -0.0554, -0.0016, -0.0353,\n",
            "        -0.1276,  0.4300,  0.0371, -0.0187,  0.0590, -0.0624, -0.0410,  0.1921,\n",
            "         0.2365, -0.1699, -0.2415, -0.1990,  0.0969, -0.0183, -0.0028,  0.2598,\n",
            "        -0.1083,  0.1324,  0.2618,  0.0304,  0.4112, -0.3221,  0.0399,  0.2097,\n",
            "        -0.0182,  0.1535, -0.0310,  0.0199, -0.1208,  0.0846, -0.0324,  0.0453,\n",
            "        -0.1271, -0.3419,  0.1232, -0.0698,  0.0407,  0.1268, -0.0695, -0.0180,\n",
            "        -0.2384, -0.2684,  0.1212, -0.3294], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 3 word\n",
            "tensor([ 0.0700, -0.0391,  0.0133, -0.2654,  0.0747,  0.0478,  0.0483,  0.4030,\n",
            "        -0.0809, -0.0044,  0.0006, -0.0440,  0.0958, -0.0132,  0.0554, -0.1726,\n",
            "         0.2175, -0.0595, -0.2384, -0.1115, -0.1137,  0.0805,  0.1035, -0.2242,\n",
            "        -0.2907,  0.0494,  0.2170, -0.0642, -0.2150,  0.0306, -0.0504,  0.0147,\n",
            "         0.2507, -0.0971, -0.0599, -0.0012, -0.3480,  0.1528, -0.2335, -0.2170,\n",
            "         0.2915, -0.0390, -0.4343,  0.1777, -0.0518,  0.1442, -0.0346, -0.2442,\n",
            "        -0.0837,  0.0125, -0.0760,  0.2040, -0.2426,  0.2165, -0.0220, -0.0318,\n",
            "        -0.0407,  0.5235,  0.0488,  0.0334,  0.0257, -0.1313,  0.2514, -0.2439,\n",
            "         0.1476, -0.1658, -0.1717, -0.1393, -0.2244, -0.2468, -0.0443,  0.0499,\n",
            "         0.0088,  0.0745,  0.0755,  0.0576,  0.1340, -0.2718,  0.0341,  0.2302,\n",
            "         0.0482,  0.0718, -0.1704,  0.0586,  0.0109, -0.1712,  0.0082,  0.2104,\n",
            "        -0.0907, -0.3293, -0.0168,  0.3038,  0.1740,  0.2986,  0.0806, -0.1114,\n",
            "         0.0784,  0.0836, -0.1453, -0.0369], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 4 word\n",
            "tensor([ 0.0657,  0.1597, -0.4079,  0.0343, -0.0987,  0.0432,  0.0780,  0.0287,\n",
            "        -0.0411, -0.1055,  0.2585, -0.3251,  0.2981, -0.0073,  0.2079,  0.0023,\n",
            "         0.1493, -0.0835, -0.1409, -0.1770, -0.3296,  0.3512, -0.3160, -0.0009,\n",
            "        -0.3819,  0.0818, -0.0152,  0.0337, -0.2058,  0.0034,  0.0081,  0.3989,\n",
            "        -0.0414,  0.0522, -0.0302, -0.1265, -0.2127, -0.2104, -0.0616, -0.1371,\n",
            "         0.2532,  0.2035, -0.0691,  0.1259,  0.1647,  0.0773, -0.1821, -0.4293,\n",
            "         0.2907,  0.0304, -0.0808,  0.3523, -0.0603,  0.3270, -0.1357,  0.2740,\n",
            "         0.2039,  0.5943,  0.0184,  0.0939, -0.0401, -0.1764, -0.0018, -0.2247,\n",
            "         0.0078, -0.3797, -0.2011, -0.0486, -0.2539, -0.0046,  0.0260, -0.0297,\n",
            "        -0.2812, -0.0648,  0.0121, -0.0935,  0.0161, -0.1133,  0.1526, -0.0037,\n",
            "         0.3293,  0.1233, -0.1179, -0.0523,  0.1630, -0.0929,  0.2372, -0.0487,\n",
            "         0.1345, -0.1545, -0.0971,  0.0575, -0.1628,  0.1281,  0.3101,  0.1039,\n",
            "        -0.3301,  0.1196, -0.0572, -0.1162], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 5 word\n",
            "tensor([-0.0675,  0.2727,  0.0528,  0.0318,  0.2123,  0.1622,  0.1305, -0.0198,\n",
            "         0.1308,  0.0275,  0.1744, -0.1362,  0.1591, -0.0969, -0.0528,  0.1311,\n",
            "        -0.4355, -0.0773,  0.0830, -0.3246,  0.1054, -0.0931, -0.2073, -0.0180,\n",
            "        -0.3182,  0.0349, -0.0631, -0.2051, -0.0112, -0.1386,  0.2735,  0.0197,\n",
            "        -0.3006, -0.1491,  0.0562,  0.1581, -0.2605,  0.0427,  0.0080,  0.1089,\n",
            "         0.4667,  0.1469,  0.1849,  0.1467, -0.0123,  0.5723,  0.0065, -0.1022,\n",
            "         0.1334,  0.3034, -0.1400,  0.0892, -0.2711, -0.0384, -0.1315, -0.0451,\n",
            "         0.0617,  0.1571, -0.1155,  0.0156, -0.1762, -0.1054, -0.0300, -0.0359,\n",
            "        -0.3446, -0.0539, -0.1475, -0.1310,  0.2363, -0.1864,  0.3311, -0.0567,\n",
            "        -0.0309, -0.3222,  0.2221, -0.0153, -0.2284, -0.3759, -0.0385, -0.0013,\n",
            "         0.3714,  0.4098, -0.3653,  0.0020, -0.0187, -0.2305,  0.1823, -0.0236,\n",
            "        -0.0931,  0.0809,  0.2724,  0.2321, -0.1055, -0.2080,  0.2355,  0.3089,\n",
            "        -0.1152,  0.4881, -0.1645, -0.3360], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 6 word\n",
            "tensor([-2.7720e-01, -1.0065e-01, -1.3006e-01, -7.7036e-02, -2.3518e-01,\n",
            "         1.1342e-01,  1.9656e-01,  8.2870e-02,  5.4271e-02,  4.9407e-01,\n",
            "        -7.0366e-02, -4.1645e-02,  4.3483e-01,  4.9503e-02,  2.1945e-03,\n",
            "        -3.8830e-02, -9.8350e-02, -1.6869e-01,  7.2941e-02, -9.3832e-02,\n",
            "         2.1033e-02,  1.3759e-01,  1.0354e-01,  5.6715e-03, -1.8920e-01,\n",
            "         3.9782e-01, -4.7751e-02,  3.3319e-01,  7.9338e-02,  3.7278e-02,\n",
            "         4.9655e-02, -2.2570e-02, -4.3849e-04, -5.0977e-02,  7.7540e-02,\n",
            "         1.9804e-02, -1.8244e-01, -2.1496e-01, -7.2171e-02,  4.3818e-02,\n",
            "         4.7023e-02,  1.2666e-01,  1.2289e-01,  2.9148e-01, -2.0592e-04,\n",
            "         2.0631e-01, -1.5412e-01, -3.1724e-01,  3.0523e-01,  7.9282e-02,\n",
            "        -2.2356e-01, -1.1756e-01, -9.8227e-02,  2.7220e-01, -2.3002e-01,\n",
            "        -6.0048e-02,  2.9628e-01,  1.4803e-01,  1.7438e-02, -2.2348e-02,\n",
            "        -1.3397e-01, -2.8610e-01,  1.2873e-01, -2.5710e-01, -1.8589e-02,\n",
            "        -1.8309e-01, -5.0682e-02, -1.4798e-01,  6.8880e-02, -4.6643e-02,\n",
            "         7.0308e-02,  3.7416e-02,  7.5165e-02, -1.0655e-01,  1.4123e-01,\n",
            "        -6.3341e-03, -1.6915e-01, -2.0463e-01,  1.6618e-01, -2.8874e-02,\n",
            "         7.2354e-02, -1.1654e-01,  9.0099e-02,  3.5014e-02,  1.5592e-01,\n",
            "        -1.6194e-01,  7.2281e-02, -1.2524e-01, -1.5439e-01, -3.7523e-02,\n",
            "         2.8008e-01,  1.4923e-01, -3.0436e-02,  1.0668e-01,  4.2143e-01,\n",
            "         3.7553e-01,  2.8072e-01,  9.7051e-02,  3.1890e-02, -2.3338e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 7 word\n",
            "tensor([-4.0656e-02, -3.1936e-02,  8.1518e-02, -1.8440e-01, -5.3657e-02,\n",
            "        -2.3833e-01,  1.9560e-01, -9.7118e-02, -3.4036e-01,  8.7601e-02,\n",
            "        -1.6551e-01, -1.2778e-01,  3.0237e-01,  1.9993e-01, -2.7297e-01,\n",
            "        -9.7768e-02, -8.0798e-02, -1.4334e-01,  3.5598e-02, -1.9765e-01,\n",
            "         3.4794e-01, -1.6050e-03,  2.9449e-03,  3.5691e-01, -9.4685e-02,\n",
            "        -1.4456e-01, -2.8290e-01, -1.3638e-01, -4.4481e-02, -3.9867e-02,\n",
            "         2.4132e-01, -9.5482e-02,  2.1134e-01, -5.0887e-03,  1.0532e-01,\n",
            "         5.6281e-02, -4.3966e-01, -7.8964e-02,  4.4113e-02, -1.4151e-01,\n",
            "        -1.0623e-01, -2.2317e-02,  2.5028e-01,  1.2806e-01, -1.2768e-02,\n",
            "         1.8880e-01, -5.1040e-02, -4.1632e-01,  2.7874e-01,  7.1173e-02,\n",
            "        -1.0905e-01,  2.4985e-02, -7.1297e-02,  1.0236e-01, -3.1651e-01,\n",
            "         5.7808e-02,  1.8123e-01,  1.7291e-01,  9.5336e-02, -5.4998e-01,\n",
            "        -2.4207e-01, -1.9838e-01,  2.1540e-01, -7.1650e-02, -9.5081e-02,\n",
            "        -9.5967e-03,  8.3513e-02, -2.2946e-01,  1.4872e-01, -9.6368e-02,\n",
            "        -5.7620e-02,  7.2458e-04, -4.0309e-02,  5.8078e-04,  2.1150e-02,\n",
            "         6.5793e-02, -3.4964e-01, -1.4986e-02, -3.5890e-02,  4.7918e-02,\n",
            "        -6.5642e-02,  7.7926e-02, -2.2310e-02,  9.3163e-02, -1.0842e-01,\n",
            "         5.5129e-02,  3.9208e-02, -2.5575e-01,  1.6868e-01, -1.0001e-01,\n",
            "         9.1058e-02,  4.7024e-02, -5.5468e-02,  5.8397e-01,  3.7051e-01,\n",
            "         3.4578e-01,  1.5278e-01,  1.7821e-01,  1.3097e-01, -3.2259e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 8 word\n",
            "tensor([ 0.0036, -0.1300, -0.2149, -0.2135, -0.0593, -0.1312, -0.2312, -0.2229,\n",
            "        -0.0267, -0.1009,  0.0359,  0.0065,  0.4636,  0.0939, -0.0404, -0.2048,\n",
            "         0.0855, -0.1905,  0.2065, -0.1653,  0.1365,  0.0423, -0.2511,  0.1822,\n",
            "        -0.3367, -0.1850,  0.0151, -0.1380, -0.1064, -0.0634,  0.2811,  0.1196,\n",
            "         0.2545,  0.2723,  0.0131, -0.1302, -0.5170,  0.0720, -0.0405, -0.0835,\n",
            "         0.1660,  0.1840,  0.0989,  0.0845, -0.4192,  0.0072,  0.0021, -0.3919,\n",
            "         0.1470,  0.2626, -0.1611, -0.0698, -0.1327,  0.0322, -0.4801, -0.0381,\n",
            "         0.2835,  0.1709, -0.1024, -0.1680,  0.2024, -0.0354,  0.2874, -0.1648,\n",
            "        -0.0079, -0.1569,  0.3929, -0.0689,  0.3187,  0.0572,  0.4066, -0.1209,\n",
            "         0.1409, -0.0344,  0.1683,  0.2692, -0.4006, -0.1036,  0.1755, -0.0054,\n",
            "        -0.1196,  0.3738,  0.0599,  0.0261, -0.1913,  0.0713,  0.1836, -0.0974,\n",
            "         0.4301, -0.0146, -0.0615, -0.0230, -0.0619,  0.2379,  0.0522,  0.3790,\n",
            "         0.0578, -0.0250,  0.0251,  0.0492], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 9 word\n",
            "tensor([-0.0052, -0.1779, -0.4359,  0.0027, -0.0398, -0.0920, -0.0038, -0.4836,\n",
            "         0.1524, -0.2986, -0.0854, -0.0307,  0.0434,  0.0095,  0.0655, -0.0107,\n",
            "         0.4189, -0.2674, -0.1227, -0.1265, -0.0182, -0.0365,  0.0043, -0.2625,\n",
            "         0.0482, -0.0906,  0.2869, -0.0571, -0.0563, -0.0569,  0.0949,  0.1627,\n",
            "         0.0871,  0.0952,  0.1733,  0.0482, -0.6066,  0.1264,  0.1772, -0.2532,\n",
            "        -0.0624, -0.1339,  0.0042,  0.0805, -0.1212,  0.0092, -0.1375, -0.1987,\n",
            "        -0.0591,  0.1444, -0.1053, -0.0643, -0.2313,  0.3364, -0.3069, -0.1895,\n",
            "        -0.0044, -0.2753,  0.1218, -0.2687,  0.1759, -0.1024, -0.1384, -0.0042,\n",
            "        -0.1288, -0.0010,  0.1963, -0.4199,  0.0141, -0.2757,  0.1619,  0.3334,\n",
            "        -0.0430,  0.1961,  0.1280, -0.0864, -0.2133, -0.2293,  0.0750,  0.3119,\n",
            "        -0.0478,  0.3865,  0.1913,  0.0867, -0.1839,  0.0647,  0.0257, -0.6163,\n",
            "         0.2717,  0.0236, -0.0098,  0.3030,  0.2823, -0.1450,  0.0388,  0.2764,\n",
            "        -0.1741, -0.2367,  0.0063, -0.1493], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 10 word\n",
            "tensor([ 0.1377,  0.2469,  0.0253,  0.2480,  0.1209, -0.1841, -0.1109,  0.0579,\n",
            "         0.4238, -0.0249, -0.1893, -0.1292, -0.1408,  0.5282,  0.5010,  0.0041,\n",
            "        -0.1408, -0.2682,  0.0039, -0.5350, -0.3451,  0.1365,  0.0306, -0.1673,\n",
            "        -0.0522,  0.0160, -0.0606, -0.2090, -0.0656, -0.2097,  0.2865,  0.0029,\n",
            "         0.1186,  0.0789, -0.0071,  0.3107, -0.1667,  0.1306, -0.0088, -0.5309,\n",
            "        -0.5954,  0.0275,  0.0469, -0.1557, -0.1929, -0.2665, -0.2023, -0.1287,\n",
            "        -0.0321,  0.2867,  0.2715, -0.0658, -0.0758,  0.1871, -0.0635, -0.1813,\n",
            "         0.0230, -0.2402,  0.0758, -0.3754,  0.2222,  0.1970,  0.1381, -0.1434,\n",
            "         0.1171,  0.2203,  0.1189, -0.4719,  0.3217, -0.0907,  0.1660,  0.4866,\n",
            "         0.2339,  0.2062, -0.1017, -0.2755, -0.2159, -0.2483,  0.2108,  0.3566,\n",
            "         0.1042,  0.1014, -0.1599,  0.0504, -0.0270, -0.0470,  0.0010,  0.0421,\n",
            "        -0.0266,  0.2876, -0.0009, -0.1126, -0.1357, -0.3458,  0.1926, -0.0196,\n",
            "        -0.0858,  0.3185, -0.1161, -0.1125], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 11 word\n",
            "tensor([-0.3423,  0.1712, -0.0539,  0.0924,  0.5170, -0.0664, -0.1703, -0.1350,\n",
            "         0.0626, -0.3425, -0.0031, -0.4063, -0.4366,  0.6000,  0.1689,  0.2182,\n",
            "        -0.1357,  0.0165,  0.4086, -0.1490,  0.2483,  0.0637, -0.0040, -0.0455,\n",
            "        -0.1173, -0.0933, -0.0409,  0.1066,  0.1802, -0.0813,  0.1180, -0.0329,\n",
            "        -0.1503, -0.1186, -0.2007,  0.2008, -0.1542, -0.0318,  0.2475,  0.0335,\n",
            "        -0.1158, -0.1872, -0.1434, -0.3331, -0.0484, -0.3047, -0.2313, -0.1284,\n",
            "        -0.2164,  0.0861,  0.0365, -0.4250,  0.0894,  0.2525,  0.3376,  0.0282,\n",
            "         0.0145, -0.2506,  0.1838,  0.0556,  0.3527,  0.3584,  0.1673, -0.0816,\n",
            "         0.2656, -0.0270,  0.1428, -0.3071,  0.2138, -0.0077,  0.0412,  0.0136,\n",
            "        -0.1392,  0.1651,  0.0306, -0.0764, -0.3232,  0.0843,  0.2831, -0.0178,\n",
            "         0.2131,  0.0319,  0.3379, -0.3184, -0.0383, -0.0874, -0.0747,  0.0315,\n",
            "        -0.0992,  0.1198, -0.4413, -0.1854, -0.0173, -0.0022, -0.5033, -0.1419,\n",
            "         0.1856,  0.1434, -0.0060,  0.0587], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 12 word\n",
            "tensor([-0.2658, -0.0465,  0.0117, -0.0024,  0.1033,  0.0998, -0.0482, -0.0733,\n",
            "        -0.2656, -0.5005, -0.2882, -0.1744, -0.1219,  0.5465, -0.1069,  0.0348,\n",
            "         0.0059,  0.4197,  0.3282, -0.2519,  0.1448,  0.0796,  0.1285,  0.0942,\n",
            "         0.1629,  0.0348, -0.0588,  0.0177,  0.1899, -0.0838,  0.2223, -0.1386,\n",
            "         0.0156, -0.0408,  0.1364, -0.1349, -0.2340,  0.1463,  0.0772,  0.0216,\n",
            "        -0.4256, -0.1678,  0.3134, -0.1571, -0.0682, -0.0359,  0.0702,  0.0797,\n",
            "         0.0271,  0.1103, -0.0732, -0.5023, -0.0804,  0.0388,  0.1292,  0.1150,\n",
            "        -0.2996, -0.4251, -0.0822,  0.1278,  0.0231,  0.0855,  0.1674,  0.1534,\n",
            "         0.1108, -0.0760,  0.1567, -0.0480,  0.3470,  0.1248,  0.1880,  0.0675,\n",
            "        -0.3846,  0.2087,  0.1688, -0.2489, -0.1620,  0.1750,  0.3616,  0.1540,\n",
            "         0.0662,  0.0291,  0.0955, -0.1570,  0.3585, -0.0929, -0.0795, -0.0606,\n",
            "        -0.0943,  0.4757, -0.1035,  0.0485, -0.0392,  0.0678, -0.0464, -0.1130,\n",
            "         0.3750,  0.1728, -0.0437, -0.1105], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 13 word\n",
            "tensor([-1.9040e-01,  1.6790e-01, -1.1704e-01,  1.8597e-01,  9.9835e-02,\n",
            "         1.8146e-01,  2.5145e-02,  2.9857e-01, -6.1483e-02, -1.5984e-01,\n",
            "         1.5536e-01, -2.2405e-01,  1.0603e-01,  5.4709e-02, -7.5363e-02,\n",
            "         1.5102e-01,  5.8162e-02, -1.1354e-01,  5.4975e-01,  1.1010e-01,\n",
            "         5.4476e-04, -1.8460e-01,  1.0743e-01,  2.5222e-02,  2.0010e-01,\n",
            "         1.4264e-01, -5.8819e-02,  4.6202e-01,  2.8634e-02, -1.7863e-02,\n",
            "         2.6210e-01, -1.0861e-01,  1.5013e-01,  4.3688e-03, -6.0698e-03,\n",
            "        -3.8923e-02, -6.0183e-02,  1.6620e-01, -5.3952e-02, -1.8469e-01,\n",
            "         6.5931e-02,  9.9572e-03, -2.3961e-01,  1.5164e-01, -1.3748e-01,\n",
            "         2.1323e-02,  7.2304e-02, -2.7798e-01,  1.2669e-01,  4.3117e-03,\n",
            "        -2.6773e-01, -5.4565e-01, -4.1605e-01, -4.2164e-02,  2.1593e-01,\n",
            "         2.4340e-02, -2.0915e-03, -1.4282e-01, -5.1029e-01, -1.8487e-02,\n",
            "        -1.6756e-01, -5.9707e-02,  4.2352e-02, -1.1763e-01,  6.5272e-03,\n",
            "         1.7029e-01,  1.7464e-01,  3.0305e-03, -5.2607e-02, -1.8774e-02,\n",
            "        -1.1026e-01, -1.8319e-01, -1.9361e-01,  6.4766e-03, -1.4523e-01,\n",
            "         1.7055e-01, -2.2427e-01,  4.9450e-02,  6.8865e-02, -1.6877e-01,\n",
            "         4.4269e-02,  3.6688e-01,  1.6989e-01,  2.1333e-01,  1.1440e-02,\n",
            "         3.0097e-01, -2.9097e-01,  1.5759e-02, -2.3789e-02,  2.4587e-01,\n",
            "        -2.2659e-01, -6.0325e-02,  1.9408e-02,  2.4120e-01, -1.8972e-01,\n",
            "        -4.1990e-01, -2.8434e-02,  5.2625e-02, -2.5736e-01, -1.8086e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 14 word\n",
            "tensor([-0.2876,  0.0154,  0.2507,  0.2388,  0.0336, -0.1550,  0.1135,  0.1557,\n",
            "        -0.0544, -0.1883,  0.0685, -0.0334,  0.0034, -0.1275, -0.1609,  0.1568,\n",
            "         0.2646,  0.0126,  0.1432, -0.0910,  0.1977, -0.1640,  0.2083,  0.2892,\n",
            "        -0.1490,  0.1404, -0.1708,  0.1852,  0.4518,  0.1131,  0.1292, -0.3415,\n",
            "        -0.0136, -0.1836, -0.0667, -0.0744, -0.0892, -0.0258, -0.0430, -0.1607,\n",
            "        -0.1099, -0.1383, -0.1947,  0.2761, -0.1166,  0.0008, -0.3760, -0.4613,\n",
            "        -0.0051, -0.0530,  0.0790, -0.0692,  0.0932, -0.1858, -0.0178,  0.0015,\n",
            "         0.0942,  0.0278, -0.2128, -0.1677, -0.0524,  0.1585,  0.4506, -0.2013,\n",
            "         0.0808, -0.1781,  0.1248, -0.2503, -0.0309,  0.0977, -0.4768, -0.1187,\n",
            "        -0.1078,  0.2760,  0.3769,  0.0417, -0.2986, -0.1286, -0.2073, -0.2798,\n",
            "         0.0555,  0.2508,  0.0134,  0.0815, -0.0071,  0.0099, -0.0739, -0.0576,\n",
            "        -0.3983,  0.2228, -0.3232,  0.0105,  0.1158,  0.3254, -0.2617, -0.0532,\n",
            "         0.3328, -0.1135,  0.2336, -0.4069], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 15 word\n",
            "tensor([-0.1746,  0.0102,  0.1569,  0.0555,  0.0940, -0.0627, -0.0221,  0.5173,\n",
            "        -0.0756,  0.0258,  0.1115,  0.1298,  0.0756, -0.2566, -0.1450,  0.4568,\n",
            "         0.0319,  0.0028,  0.2877, -0.1979, -0.0620, -0.0842,  0.2686,  0.1795,\n",
            "         0.0208, -0.2853, -0.0687, -0.1053,  0.0588,  0.3767, -0.0712, -0.0425,\n",
            "        -0.0096, -0.1688, -0.0728,  0.0290, -0.0393,  0.0119, -0.1786, -0.2420,\n",
            "        -0.0712, -0.0030, -0.0841,  0.1517, -0.3475,  0.1623, -0.1338, -0.4172,\n",
            "         0.2733, -0.0532,  0.0574, -0.0027,  0.2232, -0.0232,  0.0933, -0.0530,\n",
            "         0.0717,  0.0891, -0.2773, -0.0527, -0.1067,  0.2610,  0.1294, -0.0923,\n",
            "         0.0825, -0.1516,  0.0226, -0.0651, -0.1693, -0.0597, -0.1712, -0.0823,\n",
            "         0.1512, -0.0539, -0.0251,  0.2234, -0.0097, -0.0750,  0.1032,  0.3070,\n",
            "        -0.1374,  0.0870,  0.0824,  0.0130,  0.0608,  0.0332, -0.2046,  0.0703,\n",
            "        -0.3028, -0.3356, -0.1972,  0.2606, -0.0735,  0.2901, -0.2469, -0.1654,\n",
            "         0.0399, -0.0236,  0.0042, -0.2385], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 16 word\n",
            "tensor([-0.2122,  0.2182,  0.1543, -0.0759,  0.0313, -0.0398,  0.1653,  0.2277,\n",
            "         0.0283, -0.3039,  0.1683, -0.1526,  0.1773, -0.1470,  0.0008,  0.1336,\n",
            "         0.0476, -0.0981,  0.1194, -0.1217,  0.2947, -0.0603,  0.2037, -0.0314,\n",
            "        -0.0681, -0.2302,  0.2473, -0.2882, -0.2218,  0.0625, -0.0223,  0.2159,\n",
            "         0.1847,  0.0427,  0.0232, -0.0251,  0.3876,  0.0882, -0.0213,  0.0797,\n",
            "         0.1409, -0.2664, -0.4758, -0.0297, -0.2823,  0.0147,  0.0230, -0.4344,\n",
            "         0.3761, -0.0721,  0.0795, -0.0477,  0.1510, -0.0598,  0.2909,  0.1121,\n",
            "        -0.1506,  0.1778, -0.1054,  0.1094, -0.1151,  0.0183,  0.1453,  0.3056,\n",
            "         0.2161, -0.2026, -0.0557, -0.2432, -0.0867,  0.0178, -0.1054, -0.1586,\n",
            "         0.0398, -0.0273, -0.2077,  0.1635,  0.3196,  0.0529,  0.3157, -0.0536,\n",
            "        -0.0569, -0.0804,  0.0637,  0.0258,  0.0831, -0.0319,  0.1502, -0.0597,\n",
            "        -0.1290, -0.0459, -0.2332,  0.0541, -0.1300,  0.0540, -0.1670, -0.0518,\n",
            "         0.0838, -0.2149,  0.0949, -0.2591], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 17 word\n",
            "tensor([-5.9559e-01, -1.0672e-01,  1.2298e-01,  5.1742e-02,  2.9854e-01,\n",
            "        -9.6077e-02,  1.3904e-01,  4.4548e-01,  3.9513e-01, -5.5968e-02,\n",
            "         1.4593e-01, -3.1815e-02,  2.1188e-02,  1.5564e-01,  6.6566e-02,\n",
            "         6.9189e-02, -1.0585e-01,  9.2815e-02, -1.4174e-01, -1.5822e-01,\n",
            "        -2.8044e-01, -2.0247e-01,  2.1278e-02, -1.4307e-01, -9.4617e-02,\n",
            "        -2.3184e-01,  5.7862e-02, -3.2048e-01, -1.4097e-02, -1.2656e-01,\n",
            "         5.7260e-03,  1.2396e-01,  2.0022e-01,  8.1724e-02,  9.4378e-02,\n",
            "        -8.3804e-02,  4.3975e-01,  6.8058e-02,  1.4173e-01,  1.3567e-01,\n",
            "         1.4186e-04, -1.5648e-01, -3.1430e-01, -7.0145e-02, -9.1959e-02,\n",
            "        -1.9948e-02, -8.2297e-02, -4.1387e-02,  1.8351e-01,  3.0582e-01,\n",
            "         2.2586e-01, -4.0364e-01,  3.2090e-02, -1.0316e-02,  4.9394e-01,\n",
            "        -1.1844e-01, -6.2271e-03,  3.9464e-02,  2.0503e-02,  4.4787e-01,\n",
            "         1.6057e-01, -2.0256e-01,  4.3852e-01, -1.4450e-01,  9.6866e-02,\n",
            "        -1.0916e-01, -4.9415e-01, -3.5252e-01, -1.7888e-02,  2.1797e-01,\n",
            "        -1.8542e-01,  8.3747e-02,  1.5642e-01,  8.1286e-02,  1.8167e-01,\n",
            "         2.4436e-01,  1.9146e-01,  6.0778e-02,  2.4206e-01,  2.0552e-03,\n",
            "         1.3994e-01,  2.0355e-01, -1.8429e-02,  1.2615e-01,  2.5074e-01,\n",
            "        -7.5355e-02, -1.6136e-01, -4.6786e-02, -1.8811e-02,  6.1247e-03,\n",
            "        -1.4800e-01,  5.3068e-03,  7.4113e-02, -5.1013e-03, -1.5996e-01,\n",
            "        -1.0120e-01,  3.9229e-02,  1.8235e-01,  1.1397e-01, -3.0580e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 18 word\n",
            "tensor([-0.0604, -0.1141,  0.0702,  0.3593,  0.1703, -0.3263, -0.0009, -0.0640,\n",
            "         0.0883, -0.0281,  0.0559,  0.1186,  0.0618, -0.2311, -0.0814,  0.0675,\n",
            "        -0.1265, -0.0191, -0.0730, -0.1808, -0.1609,  0.0259, -0.1481,  0.0329,\n",
            "         0.0989, -0.2404,  0.1153, -0.0690,  0.2515, -0.1706,  0.1753,  0.2548,\n",
            "        -0.1152,  0.0086,  0.0758,  0.0880,  0.0073, -0.2508,  0.0162, -0.0424,\n",
            "        -0.1541,  0.0477,  0.0450,  0.0351,  0.0844,  0.1541, -0.0679, -0.1538,\n",
            "         0.3766,  0.0824, -0.1393, -0.0802,  0.0833, -0.3904,  0.0835,  0.0240,\n",
            "         0.0776,  0.0448, -0.0680,  0.0187, -0.0318, -0.0345,  0.5222, -0.1074,\n",
            "         0.1690, -0.1944, -0.0303, -0.2727,  0.0016,  0.0246, -0.1618,  0.0416,\n",
            "         0.1336,  0.1338,  0.4047,  0.0152,  0.3125, -0.2521,  0.4373,  0.1396,\n",
            "         0.0939,  0.0911, -0.0121, -0.0820,  0.1208, -0.2869, -0.0583, -0.1725,\n",
            "        -0.1972,  0.4201,  0.0648, -0.0014,  0.1799, -0.1087, -0.0692, -0.1964,\n",
            "         0.4550, -0.0851,  0.1805, -0.0763], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 19 word\n",
            "tensor([ 0.0965, -0.1873,  0.2941,  0.1417, -0.2024,  0.1423,  0.0796, -0.1001,\n",
            "         0.1869, -0.2439, -0.0804, -0.3073,  0.0945, -0.0198,  0.1494,  0.0895,\n",
            "         0.2315,  0.0508,  0.1170, -0.0268, -0.1091,  0.0303, -0.0099,  0.0322,\n",
            "        -0.1615, -0.1064,  0.0129, -0.1453,  0.0810, -0.2241,  0.1744,  0.2208,\n",
            "         0.2971,  0.0042,  0.2055,  0.1471,  0.0721,  0.1086, -0.1344,  0.0109,\n",
            "         0.0293,  0.1580,  0.0857,  0.2700,  0.0925, -0.0010,  0.0856,  0.0024,\n",
            "         0.0167, -0.0890, -0.0504,  0.0921, -0.0682, -0.2986,  0.2792,  0.2422,\n",
            "         0.0635, -0.0420, -0.1388, -0.0157,  0.2337, -0.0387,  0.0418,  0.2557,\n",
            "         0.4503, -0.2400, -0.1224, -0.0296, -0.1487, -0.0299, -0.1158,  0.1736,\n",
            "        -0.2453,  0.0600, -0.0485,  0.0648,  0.3468, -0.1029,  0.3431,  0.0509,\n",
            "         0.0679,  0.0170, -0.2704, -0.1612,  0.0742,  0.1225,  0.0071, -0.1537,\n",
            "        -0.0827,  0.0610, -0.2597, -0.0429,  0.1668, -0.3126,  0.0348, -0.0464,\n",
            "         0.7311, -0.1131, -0.3221, -0.0704], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 20 word\n",
            "tensor([-0.1689, -0.0142,  0.1842,  0.3278, -0.0397, -0.1009,  0.3088, -0.1942,\n",
            "        -0.0829, -0.1531, -0.4263, -0.3213,  0.0575,  0.3075, -0.0512, -0.0523,\n",
            "         0.4058,  0.0542,  0.3513, -0.2611, -0.1289, -0.0891,  0.2041,  0.1964,\n",
            "         0.0263,  0.0554, -0.1243, -0.0188,  0.4873,  0.1913, -0.2298,  0.0913,\n",
            "         0.0725,  0.1845,  0.1076,  0.1012,  0.4029,  0.2381, -0.1244,  0.0626,\n",
            "        -0.0322, -0.0851, -0.0651,  0.4515, -0.1193, -0.0600, -0.0661, -0.2054,\n",
            "        -0.2752, -0.3149,  0.1555, -0.1514,  0.0241, -0.0481,  0.1922,  0.0693,\n",
            "         0.0198,  0.1780, -0.2725,  0.0230, -0.0470,  0.0259, -0.0237,  0.0998,\n",
            "         0.3351, -0.3502, -0.2132, -0.1429, -0.0345, -0.0022,  0.0334, -0.1184,\n",
            "        -0.1300,  0.4429,  0.1549,  0.2380,  0.1391, -0.2989,  0.2112,  0.3048,\n",
            "        -0.0304, -0.4877, -0.0510, -0.3122,  0.0081,  0.3564, -0.1541, -0.2316,\n",
            "        -0.2859,  0.0622, -0.1892, -0.0062,  0.2650,  0.0725,  0.4841, -0.3686,\n",
            "         0.2953, -0.3570, -0.1912,  0.0322], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 21 word\n",
            "tensor([-0.0920,  0.3692,  0.2651,  0.1186, -0.2833, -0.0266,  0.0361,  0.3213,\n",
            "         0.3090, -0.0080, -0.0233, -0.0084,  0.1964, -0.0616, -0.0623,  0.0241,\n",
            "         0.0819,  0.0310, -0.0621, -0.3237, -0.3383, -0.1136, -0.0698,  0.0472,\n",
            "         0.1067, -0.0842, -0.3065,  0.1823,  0.1607,  0.2032,  0.1455,  0.4896,\n",
            "         0.1036, -0.0159,  0.2147,  0.0922,  0.0430, -0.0326, -0.1618,  0.3263,\n",
            "        -0.4573, -0.0653, -0.2125,  0.1674, -0.0515, -0.1782,  0.0339,  0.0720,\n",
            "        -0.0281,  0.0165,  0.0418,  0.0650,  0.2363, -0.0063,  0.1518,  0.0422,\n",
            "        -0.1174,  0.2302,  0.1320, -0.3317,  0.0674,  0.0094,  0.0208, -0.0307,\n",
            "         0.1672,  0.3071, -0.2706,  0.0067, -0.0942, -0.1251,  0.0260, -0.1949,\n",
            "        -0.1151, -0.0036,  0.1534,  0.1137,  0.3649, -0.3793,  0.5487,  0.0377,\n",
            "        -0.1161,  0.1202, -0.0568,  0.0864, -0.2818,  0.0833,  0.2260, -0.3294,\n",
            "        -0.1817,  0.2571, -0.2062,  0.2211,  0.4248, -0.3214,  0.0853,  0.0301,\n",
            "         0.1254,  0.0592, -0.1741, -0.0672], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 22 word\n",
            "tensor([-0.1323,  0.1549,  0.1060, -0.0212, -0.2698, -0.1613,  0.0955,  0.1664,\n",
            "         0.0663, -0.3258, -0.0189,  0.1641,  0.0746, -0.3307, -0.0262, -0.1650,\n",
            "         0.0201,  0.2337,  0.0778,  0.0378, -0.0045, -0.0484, -0.2530, -0.0327,\n",
            "        -0.3203, -0.2043, -0.0238, -0.1566, -0.0163,  0.1987,  0.2239,  0.1406,\n",
            "         0.0327,  0.0608, -0.0341, -0.1063,  0.0721,  0.3962, -0.0666,  0.5255,\n",
            "        -0.1063, -0.4677,  0.1261,  0.3395,  0.1404, -0.0123, -0.0301, -0.1145,\n",
            "        -0.3126, -0.1634, -0.2004,  0.0317,  0.2255, -0.2063,  0.2716, -0.1368,\n",
            "        -0.1241,  0.3641,  0.0642,  0.0260, -0.0564, -0.3244,  0.2436,  0.0199,\n",
            "         0.0533, -0.2315, -0.1067,  0.2553, -0.0342, -0.4091, -0.1030, -0.0793,\n",
            "         0.0079, -0.1480,  0.2555,  0.0869,  0.0726,  0.1334,  0.1157,  0.2014,\n",
            "        -0.1702,  0.0582,  0.0076,  0.1748, -0.6665,  0.4652,  0.1129, -0.3181,\n",
            "        -0.4032,  0.1743, -0.2764,  0.2410,  0.1293,  0.0809,  0.2330,  0.0368,\n",
            "         0.1225,  0.2538,  0.0352, -0.1126], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 23 word\n",
            "tensor([ 0.0201,  0.3234,  0.0502, -0.1131, -0.0070, -0.1065,  0.0737,  0.0305,\n",
            "         0.5017, -0.0875, -0.3196,  0.0661,  0.1306, -0.2584, -0.2122, -0.1075,\n",
            "         0.0323,  0.0251,  0.1464,  0.1085, -0.1991, -0.0267, -0.0869, -0.0971,\n",
            "        -0.2600, -0.1287, -0.0102, -0.1687, -0.1689, -0.0565,  0.0984, -0.1376,\n",
            "        -0.0460,  0.0362, -0.0462,  0.0603,  0.2080,  0.2007, -0.1886,  0.5521,\n",
            "         0.0553,  0.0493,  0.1114,  0.0534,  0.4499,  0.0074, -0.1390, -0.5272,\n",
            "         0.0118,  0.0470, -0.1036,  0.4856,  0.1004, -0.4023,  0.4062,  0.2096,\n",
            "        -0.0317, -0.0586,  0.2013, -0.3304, -0.1543,  0.0153,  0.1953,  0.1874,\n",
            "        -0.0156,  0.1972, -0.0906,  0.2491,  0.2821, -0.3502, -0.0350, -0.0168,\n",
            "        -0.0390, -0.2515, -0.0164, -0.1609, -0.2233,  0.2882,  0.1648,  0.4911,\n",
            "        -0.1436,  0.1112, -0.0029,  0.1714, -0.4293,  0.1050,  0.1385,  0.0399,\n",
            "        -0.0975,  0.2060,  0.3516,  0.3557,  0.1375,  0.1351,  0.2920, -0.0825,\n",
            "        -0.1308,  0.1757, -0.3853, -0.2685], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 24 word\n",
            "tensor([ 0.5238, -0.0859,  0.1276,  0.0931, -0.2662, -0.2144,  0.0022,  0.4979,\n",
            "         0.0900, -0.0334,  0.0612, -0.0083, -0.0875,  0.0149, -0.1560, -0.1690,\n",
            "        -0.1361,  0.1036,  0.0034,  0.0453, -0.0206, -0.0220, -0.2060, -0.2784,\n",
            "        -0.2216, -0.3563, -0.4187, -0.3089, -0.1012, -0.0481,  0.4159, -0.1888,\n",
            "         0.1205, -0.0613, -0.0767,  0.0834,  0.1966,  0.7267, -0.5051,  0.2453,\n",
            "        -0.1042, -0.0889,  0.5321, -0.0025,  0.2278, -0.0766, -0.1902,  0.1304,\n",
            "         0.0044,  0.1205, -0.2463,  0.1447,  0.1270, -0.0710,  0.2965, -0.0764,\n",
            "         0.0689, -0.0129,  0.0918, -0.5079, -0.1759,  0.0354, -0.1514,  0.4952,\n",
            "         0.1006,  0.1071,  0.0512,  0.2135, -0.0118, -0.3334,  0.3370, -0.0479,\n",
            "         0.2566, -0.1675,  0.0300, -0.0634,  0.0964,  0.0968, -0.1060,  0.2368,\n",
            "         0.0798, -0.0062, -0.0329, -0.0639, -0.1589, -0.0118, -0.0433, -0.0165,\n",
            "        -0.0594,  0.3798,  0.3247,  0.1998, -0.0819,  0.1379, -0.2385, -0.3075,\n",
            "        -0.2165,  0.0692, -0.0090, -0.0092], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 25 word\n",
            "tensor([ 0.2570, -0.0168, -0.0112,  0.1267, -0.0497,  0.1214,  0.1067,  0.1589,\n",
            "         0.3322, -0.0339,  0.0608,  0.1353,  0.0659, -0.1003, -0.2590, -0.0435,\n",
            "        -0.3140,  0.0755, -0.1063, -0.1187, -0.1667,  0.1951, -0.3742, -0.4471,\n",
            "        -0.1041, -0.0848, -0.1761, -0.2409, -0.2293, -0.2984,  0.4295, -0.3658,\n",
            "         0.0349, -0.0789, -0.0733, -0.1963, -0.1180,  0.1174, -0.2254,  0.3652,\n",
            "         0.0449,  0.0191,  0.2010,  0.0982,  0.4173, -0.0796, -0.0582,  0.0582,\n",
            "        -0.3693,  0.3654,  0.2156,  0.2761, -0.0626, -0.3022,  0.4451, -0.3286,\n",
            "         0.1132, -0.0187,  0.1295, -0.1946, -0.0768,  0.2124,  0.0409,  0.1794,\n",
            "         0.1976,  0.2937, -0.0030,  0.0761,  0.1583, -0.0218,  0.0900,  0.1091,\n",
            "        -0.0514, -0.0940, -0.0193,  0.2242, -0.2919,  0.0884, -0.0090,  0.4266,\n",
            "         0.0442, -0.2125, -0.0695,  0.1824, -0.0980, -0.0290, -0.1653, -0.0303,\n",
            "        -0.0414,  0.2692,  0.0532,  0.2480, -0.2728,  0.2724, -0.5624, -0.2963,\n",
            "        -0.0164,  0.0935,  0.1291, -0.0821], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 26 word\n",
            "tensor([ 0.0417,  0.0277, -0.0445,  0.0351, -0.1412, -0.1808,  0.0575,  0.0530,\n",
            "         0.2151, -0.1485, -0.1244,  0.1571, -0.0653,  0.0540, -0.0005, -0.1859,\n",
            "        -0.3008,  0.0789, -0.1555, -0.1277, -0.0658,  0.0570, -0.2383, -0.2077,\n",
            "        -0.0416,  0.1169, -0.1993, -0.1835, -0.4346, -0.0900,  0.1680, -0.2745,\n",
            "         0.3557,  0.0370,  0.0876, -0.1413, -0.1992, -0.0544,  0.1719,  0.2274,\n",
            "        -0.1459, -0.1978,  0.0671,  0.3874,  0.0831, -0.0357,  0.0596, -0.2364,\n",
            "        -0.3715, -0.0678,  0.0601,  0.0817, -0.0208, -0.1021, -0.0354, -0.2450,\n",
            "         0.1748, -0.0570,  0.2168,  0.0955, -0.0539,  0.2043,  0.2159,  0.1399,\n",
            "        -0.0093,  0.1030,  0.1643,  0.1209,  0.0514,  0.1211,  0.0796, -0.1822,\n",
            "        -0.0610, -0.0825,  0.0423,  0.0023, -0.1854, -0.0836,  0.0034, -0.0277,\n",
            "         0.1589, -0.1227, -0.1090,  0.5055, -0.0430, -0.0953, -0.2842,  0.2033,\n",
            "        -0.1469,  0.1679, -0.0907,  0.1607, -0.2037,  0.0698,  0.0611, -0.3239,\n",
            "        -0.0481,  0.0283,  0.0986,  0.0490], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 27 word\n",
            "tensor([ 0.2531, -0.1123,  0.2227,  0.0933,  0.0371, -0.1550, -0.1013, -0.0741,\n",
            "         0.1049, -0.1272, -0.2172,  0.4550, -0.2337,  0.0674, -0.1096, -0.0334,\n",
            "        -0.3750,  0.0902,  0.0143, -0.0023, -0.0884,  0.2994, -0.1453, -0.2214,\n",
            "         0.1930,  0.2685, -0.4236, -0.1915,  0.2297, -0.0942,  0.1669, -0.1273,\n",
            "         0.3690,  0.0778,  0.1152, -0.0336, -0.1779,  0.1826,  0.1981,  0.3104,\n",
            "         0.0076,  0.0703,  0.0698,  0.3241,  0.1196,  0.1937, -0.0097,  0.1650,\n",
            "         0.0203,  0.1059,  0.0865,  0.1525,  0.0229,  0.1868,  0.1958, -0.1439,\n",
            "         0.2280, -0.1580,  0.0644, -0.0781, -0.1603,  0.0340, -0.4286, -0.0741,\n",
            "        -0.2457,  0.0079, -0.0141, -0.0503,  0.0103,  0.1364,  0.0022,  0.0172,\n",
            "         0.3807, -0.2750, -0.0839,  0.1379,  0.1599,  0.1099, -0.2610,  0.1783,\n",
            "         0.0866, -0.0330,  0.1448,  0.1112,  0.1962, -0.0430, -0.1897, -0.0113,\n",
            "         0.0286, -0.1456,  0.0155,  0.1606, -0.2045, -0.0057,  0.2624,  0.1777,\n",
            "        -0.3310, -0.0619,  0.2141,  0.0872], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 28 word\n",
            "tensor([ 0.0127, -0.0911, -0.1573,  0.0472, -0.0255, -0.1687,  0.0220, -0.2117,\n",
            "         0.1971, -0.2492, -0.1388,  0.0381, -0.0355, -0.0148,  0.0418,  0.0717,\n",
            "         0.1796,  0.0215, -0.2218, -0.0871, -0.0911,  0.1145,  0.0187, -0.2873,\n",
            "         0.0890,  0.0851, -0.3801, -0.0612,  0.1361,  0.0662,  0.1023, -0.1093,\n",
            "         0.0710,  0.0683,  0.2909,  0.0434, -0.4727,  0.2123,  0.3661,  0.0384,\n",
            "        -0.0698, -0.1427,  0.0432,  0.0610,  0.0888,  0.0823, -0.1532, -0.1766,\n",
            "        -0.0741,  0.1352,  0.1390,  0.0075, -0.0758,  0.3976, -0.0487, -0.2015,\n",
            "        -0.1055, -0.3489,  0.2694, -0.1414, -0.0393, -0.0884, -0.3663,  0.0291,\n",
            "        -0.1598,  0.0956, -0.2541, -0.4030, -0.0042, -0.2839, -0.0531,  0.3555,\n",
            "        -0.0078,  0.0786,  0.1074, -0.1128,  0.2583, -0.1371, -0.1546,  0.3547,\n",
            "         0.0341,  0.2714,  0.2315,  0.0850,  0.0170,  0.0543, -0.1110, -0.5303,\n",
            "         0.0609, -0.0446,  0.1165,  0.4373,  0.0874, -0.2101,  0.0426,  0.1314,\n",
            "        -0.4713, -0.2191,  0.0817, -0.1510], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 29 word\n",
            "tensor([ 0.1491,  0.0580, -0.0676,  0.2104, -0.0817, -0.1278,  0.4117, -0.1109,\n",
            "        -0.1113,  0.2271, -0.1642, -0.1567,  0.0877, -0.0467,  0.4349,  0.0060,\n",
            "         0.4099, -0.1335,  0.0475, -0.1376,  0.2417, -0.4041, -0.0048, -0.2389,\n",
            "         0.2748,  0.1924, -0.0529, -0.6224,  0.2830,  0.0590,  0.0049, -0.4399,\n",
            "        -0.0338,  0.0180,  0.1959, -0.1920, -0.0196,  0.0304,  0.0654, -0.0670,\n",
            "        -0.5140,  0.0077, -0.0926,  0.1970,  0.2004, -0.0406, -0.1495, -0.0618,\n",
            "        -0.2134,  0.0794,  0.3420,  0.0053, -0.1775, -0.1208,  0.1874, -0.0883,\n",
            "        -0.2994,  0.1512,  0.2217, -0.0994, -0.0316,  0.0034, -0.0279, -0.1601,\n",
            "        -0.0825, -0.0823,  0.1147, -0.4716, -0.1912,  0.0043,  0.0129,  0.2127,\n",
            "         0.3625, -0.0307,  0.0656, -0.4852,  0.1461, -0.1316,  0.0808,  0.0250,\n",
            "        -0.1043,  0.1503, -0.0414, -0.0530, -0.0985,  0.4098, -0.0011, -0.0040,\n",
            "        -0.1635, -0.0921, -0.0075, -0.0083,  0.0419, -0.0299,  0.0950, -0.0469,\n",
            "         0.0557, -0.1025, -0.0130, -0.3490], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 30 word\n",
            "tensor([-2.2520e-01,  3.9067e-01, -1.8569e-01,  3.6676e-01,  4.5229e-02,\n",
            "        -3.0505e-02,  2.8821e-01, -3.0735e-02, -6.0457e-02,  5.3826e-02,\n",
            "        -8.3242e-02, -5.2007e-03,  3.9359e-01, -2.9558e-02,  1.1042e-01,\n",
            "        -4.0869e-02,  9.2931e-02, -1.2460e-01,  1.6947e-01,  6.7817e-02,\n",
            "         2.6154e-01, -3.3382e-01,  2.9603e-01, -1.0894e-01,  2.3135e-01,\n",
            "         8.3420e-02,  1.7234e-01, -6.0717e-01,  2.8207e-01, -5.9554e-02,\n",
            "        -2.4573e-01, -6.0612e-01,  1.3594e-01, -2.6460e-02,  2.8387e-01,\n",
            "        -8.8286e-03, -4.7222e-02, -1.0058e-01, -7.8864e-02, -2.8834e-02,\n",
            "         1.2247e-01, -3.8491e-02, -6.6337e-02,  2.5121e-01,  1.4704e-01,\n",
            "        -1.7743e-01, -2.6126e-02,  1.2937e-01, -2.3782e-01, -2.6507e-01,\n",
            "        -8.2012e-02,  3.2049e-02,  1.8136e-01, -7.2636e-02,  1.4708e-01,\n",
            "         4.7335e-02, -2.0335e-01,  5.0021e-01,  4.9939e-01, -2.0465e-01,\n",
            "         1.3501e-01,  8.1893e-02,  3.6533e-02, -1.3724e-01,  1.1503e-01,\n",
            "         1.2498e-01,  3.6896e-01, -4.4770e-03, -5.0555e-02,  5.4697e-02,\n",
            "        -1.5775e-01,  1.5781e-01, -2.0932e-01, -2.4223e-04, -3.7951e-01,\n",
            "         1.5824e-01,  1.7254e-01, -3.3334e-01, -1.4460e-01,  2.9962e-01,\n",
            "        -1.7765e-02, -1.7092e-02, -3.9585e-02, -1.6967e-02,  1.0808e-01,\n",
            "         1.7138e-01, -5.7650e-02,  1.4694e-01,  1.6493e-02, -3.0910e-01,\n",
            "         1.3512e-01,  3.6129e-02, -5.3534e-02, -2.3063e-01,  6.3502e-02,\n",
            "         1.4788e-02,  2.5390e-01, -9.7817e-02,  1.7675e-01, -3.2889e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "after 31 word\n",
            "tensor([-3.4800e-02,  8.5655e-02, -3.8180e-01,  6.1931e-02, -1.9269e-02,\n",
            "        -1.3462e-01,  1.6974e-01, -2.3355e-01,  4.0454e-03, -1.1560e-01,\n",
            "        -1.4438e-01, -3.8807e-02,  1.9904e-02, -3.8653e-02,  7.6191e-02,\n",
            "         6.4488e-02,  4.1707e-01, -1.3892e-01, -1.5829e-01, -6.6365e-02,\n",
            "         1.4042e-02, -2.2403e-01,  1.0375e-01, -3.3547e-01,  1.2169e-01,\n",
            "         3.7110e-02,  4.2141e-01, -1.4920e-01,  9.3085e-02,  6.1911e-02,\n",
            "        -2.9055e-01, -2.7093e-01,  3.8183e-02,  4.8379e-02,  3.5246e-01,\n",
            "         4.0569e-02, -4.4058e-01, -1.0262e-01,  1.2236e-01, -1.9489e-01,\n",
            "        -5.6071e-02, -2.2044e-01, -8.6371e-02,  2.7637e-02,  8.1223e-02,\n",
            "        -6.0619e-02, -1.6638e-01, -8.9791e-02, -9.2830e-02,  9.0866e-02,\n",
            "        -5.2892e-02, -1.2142e-02, -7.4252e-02,  2.6176e-01, -2.8039e-02,\n",
            "        -1.2039e-01, -5.1710e-01, -2.5648e-01,  2.9561e-01, -2.9240e-01,\n",
            "         1.2025e-01, -9.2692e-02, -2.0428e-01,  1.9015e-02, -9.6663e-02,\n",
            "         1.5969e-01,  3.0052e-02, -4.0268e-01, -1.0580e-02, -2.6326e-01,\n",
            "        -1.7148e-01,  4.5529e-01, -7.0794e-02,  2.3484e-01,  7.7814e-03,\n",
            "        -6.9742e-02,  3.6854e-01, -2.6573e-01, -1.1142e-02,  3.8692e-01,\n",
            "        -4.4402e-04,  2.9298e-01, -4.1378e-02, -1.2071e-02, -1.9612e-02,\n",
            "         6.9179e-02, -4.9200e-02, -3.9477e-01,  5.5642e-02, -1.1180e-01,\n",
            "         1.3985e-01,  3.3163e-01,  2.9820e-01, -2.8862e-01,  3.5921e-02,\n",
            "         8.5790e-02,  1.9029e-03, -2.5800e-01,  1.5976e-01, -2.9575e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "\n",
            "Encoder LSTM final hidden vector\n",
            "tensor([[[-3.4800e-02,  8.5655e-02, -3.8180e-01,  6.1931e-02, -1.9269e-02,\n",
            "          -1.3462e-01,  1.6974e-01, -2.3355e-01,  4.0454e-03, -1.1560e-01,\n",
            "          -1.4438e-01, -3.8807e-02,  1.9904e-02, -3.8653e-02,  7.6191e-02,\n",
            "           6.4488e-02,  4.1707e-01, -1.3892e-01, -1.5829e-01, -6.6365e-02,\n",
            "           1.4042e-02, -2.2403e-01,  1.0375e-01, -3.3547e-01,  1.2169e-01,\n",
            "           3.7110e-02,  4.2141e-01, -1.4920e-01,  9.3085e-02,  6.1911e-02,\n",
            "          -2.9055e-01, -2.7093e-01,  3.8183e-02,  4.8379e-02,  3.5246e-01,\n",
            "           4.0569e-02, -4.4058e-01, -1.0262e-01,  1.2236e-01, -1.9489e-01,\n",
            "          -5.6071e-02, -2.2044e-01, -8.6371e-02,  2.7637e-02,  8.1223e-02,\n",
            "          -6.0619e-02, -1.6638e-01, -8.9791e-02, -9.2830e-02,  9.0866e-02,\n",
            "          -5.2892e-02, -1.2142e-02, -7.4252e-02,  2.6176e-01, -2.8039e-02,\n",
            "          -1.2039e-01, -5.1710e-01, -2.5648e-01,  2.9561e-01, -2.9240e-01,\n",
            "           1.2025e-01, -9.2692e-02, -2.0428e-01,  1.9015e-02, -9.6663e-02,\n",
            "           1.5969e-01,  3.0052e-02, -4.0268e-01, -1.0580e-02, -2.6326e-01,\n",
            "          -1.7148e-01,  4.5529e-01, -7.0794e-02,  2.3484e-01,  7.7814e-03,\n",
            "          -6.9742e-02,  3.6854e-01, -2.6573e-01, -1.1142e-02,  3.8692e-01,\n",
            "          -4.4402e-04,  2.9298e-01, -4.1378e-02, -1.2071e-02, -1.9612e-02,\n",
            "           6.9179e-02, -4.9200e-02, -3.9477e-01,  5.5642e-02, -1.1180e-01,\n",
            "           1.3985e-01,  3.3163e-01,  2.9820e-01, -2.8862e-01,  3.5921e-02,\n",
            "           8.5790e-02,  1.9029e-03, -2.5800e-01,  1.5976e-01, -2.9575e-01]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "\n",
            "Decoder LSTM output vector after each time step(total 3 time steps)\n",
            "after 1 time step\n",
            "tensor([[-0.0011,  0.0257, -0.0573,  0.0335,  0.0447,  0.0298,  0.0015,  0.0515,\n",
            "         -0.0163,  0.0179, -0.0254,  0.0487, -0.0094, -0.0073,  0.0394, -0.0064,\n",
            "          0.0453,  0.0083,  0.0085, -0.0386, -0.0196, -0.0104,  0.0490, -0.0398,\n",
            "          0.0492, -0.0186, -0.0322, -0.0086,  0.0464, -0.0333, -0.0014, -0.0131,\n",
            "         -0.0510, -0.0059, -0.0143,  0.0234, -0.0629, -0.0450, -0.0449,  0.0555,\n",
            "          0.0141, -0.0401, -0.0355, -0.0446, -0.0819,  0.0276, -0.0856, -0.0529,\n",
            "         -0.0120,  0.0227,  0.0479,  0.0171, -0.0298,  0.0081, -0.0301, -0.0869,\n",
            "         -0.0388, -0.0094, -0.0176,  0.0066,  0.0312,  0.0252, -0.0235, -0.0675,\n",
            "          0.0418,  0.0210, -0.0321, -0.0148, -0.0671,  0.0442, -0.0207,  0.0275,\n",
            "          0.0415, -0.0197,  0.0118, -0.0054,  0.0192, -0.0233,  0.0229,  0.0154,\n",
            "          0.0450,  0.0480, -0.0319, -0.0088,  0.0628, -0.0265, -0.0130,  0.0351,\n",
            "         -0.0010,  0.0030, -0.0076,  0.0069,  0.0128,  0.0004,  0.0635, -0.0491,\n",
            "         -0.0400,  0.0004,  0.0310,  0.0181]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 2 time step\n",
            "tensor([[-0.0059,  0.0427, -0.0877,  0.0520,  0.0599,  0.0457,  0.0058,  0.0787,\n",
            "         -0.0237,  0.0240, -0.0399,  0.0772, -0.0124, -0.0154,  0.0581, -0.0124,\n",
            "          0.0648,  0.0114,  0.0189, -0.0548, -0.0236, -0.0200,  0.0798, -0.0644,\n",
            "          0.0863, -0.0239, -0.0371, -0.0129,  0.0777, -0.0377, -0.0062, -0.0197,\n",
            "         -0.0736, -0.0047, -0.0165,  0.0317, -0.0910, -0.0627, -0.0675,  0.0820,\n",
            "          0.0254, -0.0604, -0.0572, -0.0594, -0.1188,  0.0372, -0.1269, -0.0795,\n",
            "         -0.0156,  0.0258,  0.0806,  0.0315, -0.0498,  0.0132, -0.0498, -0.1224,\n",
            "         -0.0505, -0.0176, -0.0262,  0.0037,  0.0481,  0.0347, -0.0362, -0.0907,\n",
            "          0.0562,  0.0296, -0.0486, -0.0242, -0.0981,  0.0642, -0.0271,  0.0436,\n",
            "          0.0648, -0.0314,  0.0078, -0.0046,  0.0320, -0.0340,  0.0351,  0.0266,\n",
            "          0.0644,  0.0715, -0.0458, -0.0186,  0.0963, -0.0422, -0.0174,  0.0515,\n",
            "         -0.0107,  0.0007, -0.0116,  0.0124,  0.0193, -0.0026,  0.0973, -0.0725,\n",
            "         -0.0615, -0.0119,  0.0512,  0.0183]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "after 3 time step\n",
            "tensor([[-9.8051e-03,  5.2311e-02, -1.0306e-01,  6.2561e-02,  6.4110e-02,\n",
            "          5.3055e-02,  8.8216e-03,  9.3003e-02, -2.7218e-02,  2.6442e-02,\n",
            "         -4.9027e-02,  9.2470e-02, -1.3839e-02, -2.1809e-02,  6.6484e-02,\n",
            "         -1.7853e-02,  7.3074e-02,  1.2328e-02,  2.7067e-02, -6.1695e-02,\n",
            "         -2.2947e-02, -2.6596e-02,  9.8555e-02, -7.9117e-02,  1.1120e-01,\n",
            "         -2.4323e-02, -3.2286e-02, -1.5529e-02,  9.8099e-02, -3.3371e-02,\n",
            "         -1.0299e-02, -2.2292e-02, -8.3602e-02, -1.0278e-03, -1.4815e-02,\n",
            "          3.3730e-02, -1.0403e-01, -6.9918e-02, -7.9521e-02,  9.4443e-02,\n",
            "          3.3479e-02, -7.1923e-02, -6.9333e-02, -6.4180e-02, -1.3528e-01,\n",
            "          4.0027e-02, -1.4646e-01, -9.3135e-02, -1.6150e-02,  2.2654e-02,\n",
            "          1.0101e-01,  4.1745e-02, -6.1895e-02,  1.7390e-02, -6.0634e-02,\n",
            "         -1.3662e-01, -5.3888e-02, -2.2522e-02, -3.0368e-02,  6.3255e-05,\n",
            "          5.8149e-02,  3.8420e-02, -4.4343e-02, -9.7362e-02,  6.0848e-02,\n",
            "          3.2852e-02, -5.6554e-02, -3.0985e-02, -1.1227e-01,  7.2420e-02,\n",
            "         -2.8477e-02,  5.2332e-02,  7.6845e-02, -3.7777e-02,  1.5889e-03,\n",
            "         -2.1012e-03,  3.9777e-02, -3.8065e-02,  4.1302e-02,  3.2243e-02,\n",
            "          7.3516e-02,  8.3682e-02, -5.1471e-02, -2.6331e-02,  1.1565e-01,\n",
            "         -5.1134e-02, -1.7965e-02,  5.8716e-02, -1.9628e-02, -3.3651e-03,\n",
            "         -1.3053e-02,  1.5331e-02,  2.1225e-02, -4.8036e-03,  1.1438e-01,\n",
            "         -8.3103e-02, -7.2445e-02, -2.2370e-02,  6.4127e-02,  1.4075e-02]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "\n",
            "Decoder LSTM final hidden vector\n",
            "tensor([[-9.8051e-03,  5.2311e-02, -1.0306e-01,  6.2561e-02,  6.4110e-02,\n",
            "          5.3055e-02,  8.8216e-03,  9.3003e-02, -2.7218e-02,  2.6442e-02,\n",
            "         -4.9027e-02,  9.2470e-02, -1.3839e-02, -2.1809e-02,  6.6484e-02,\n",
            "         -1.7853e-02,  7.3074e-02,  1.2328e-02,  2.7067e-02, -6.1695e-02,\n",
            "         -2.2947e-02, -2.6596e-02,  9.8555e-02, -7.9117e-02,  1.1120e-01,\n",
            "         -2.4323e-02, -3.2286e-02, -1.5529e-02,  9.8099e-02, -3.3371e-02,\n",
            "         -1.0299e-02, -2.2292e-02, -8.3602e-02, -1.0278e-03, -1.4815e-02,\n",
            "          3.3730e-02, -1.0403e-01, -6.9918e-02, -7.9521e-02,  9.4443e-02,\n",
            "          3.3479e-02, -7.1923e-02, -6.9333e-02, -6.4180e-02, -1.3528e-01,\n",
            "          4.0027e-02, -1.4646e-01, -9.3135e-02, -1.6150e-02,  2.2654e-02,\n",
            "          1.0101e-01,  4.1745e-02, -6.1895e-02,  1.7390e-02, -6.0634e-02,\n",
            "         -1.3662e-01, -5.3888e-02, -2.2522e-02, -3.0368e-02,  6.3255e-05,\n",
            "          5.8149e-02,  3.8420e-02, -4.4343e-02, -9.7362e-02,  6.0848e-02,\n",
            "          3.2852e-02, -5.6554e-02, -3.0985e-02, -1.1227e-01,  7.2420e-02,\n",
            "         -2.8477e-02,  5.2332e-02,  7.6845e-02, -3.7777e-02,  1.5889e-03,\n",
            "         -2.1012e-03,  3.9777e-02, -3.8065e-02,  4.1302e-02,  3.2243e-02,\n",
            "          7.3516e-02,  8.3682e-02, -5.1471e-02, -2.6331e-02,  1.1565e-01,\n",
            "         -5.1134e-02, -1.7965e-02,  5.8716e-02, -1.9628e-02, -3.3651e-03,\n",
            "         -1.3053e-02,  1.5331e-02,  2.1225e-02, -4.8036e-03,  1.1438e-01,\n",
            "         -8.3103e-02, -7.2445e-02, -2.2370e-02,  6.4127e-02,  1.4075e-02]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "\n",
            "Final vector after FC layer\n",
            "tensor([[0.0021, 0.9959, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3LmDYHrW5Ss"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}